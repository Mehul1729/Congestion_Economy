{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b885133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc39879d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting osmnx\n",
      "  Downloading osmnx-2.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting geopandas>=1.0.1 (from osmnx)\n",
      "  Downloading geopandas-1.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: networkx>=2.5 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from osmnx) (3.5)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from osmnx) (2.2.0)\n",
      "Requirement already satisfied: pandas>=1.4 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from osmnx) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.27 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from osmnx) (2.32.5)\n",
      "Collecting shapely>=2.0 (from osmnx)\n",
      "  Using cached shapely-2.1.2-cp312-cp312-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas>=1.0.1->osmnx)\n",
      "  Downloading pyogrio-0.11.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: packaging in c:\\conda\\envs\\pyenv\\lib\\site-packages (from geopandas>=1.0.1->osmnx) (25.0)\n",
      "Collecting pyproj>=3.5.0 (from geopandas>=1.0.1->osmnx)\n",
      "  Downloading pyproj-3.7.2-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from pandas>=1.4->osmnx) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from pandas>=1.4->osmnx) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from pandas>=1.4->osmnx) (2025.2)\n",
      "Requirement already satisfied: certifi in c:\\conda\\envs\\pyenv\\lib\\site-packages (from pyogrio>=0.7.2->geopandas>=1.0.1->osmnx) (2025.10.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from requests>=2.27->osmnx) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from requests>=2.27->osmnx) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from requests>=2.27->osmnx) (2.5.0)\n",
      "Downloading osmnx-2.0.6-py3-none-any.whl (101 kB)\n",
      "Downloading geopandas-1.1.1-py3-none-any.whl (338 kB)\n",
      "Downloading pyogrio-0.11.1-cp312-cp312-win_amd64.whl (19.2 MB)\n",
      "   ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/19.2 MB 8.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.9/19.2 MB 8.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 5.5/19.2 MB 9.1 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 6.8/19.2 MB 8.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 8.1/19.2 MB 8.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 10.0/19.2 MB 8.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 11.3/19.2 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 12.3/19.2 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 13.9/19.2 MB 7.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 15.7/19.2 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 17.8/19.2 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.2/19.2 MB 7.7 MB/s  0:00:02\n",
      "Downloading pyproj-3.7.2-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.3 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.4/6.3 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.2/6.3 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.5/6.3 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 6.7 MB/s  0:00:00\n",
      "Using cached shapely-2.1.2-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "Installing collected packages: shapely, pyproj, pyogrio, geopandas, osmnx\n",
      "\n",
      "   ---------------------------------------- 0/5 [shapely]\n",
      "   ---------------------------------------- 0/5 [shapely]\n",
      "   ---------------------------------------- 0/5 [shapely]\n",
      "   ---------------------------------------- 0/5 [shapely]\n",
      "   ---------------------------------------- 0/5 [shapely]\n",
      "   ---------------------------------------- 0/5 [shapely]\n",
      "   ---------------------------------------- 0/5 [shapely]\n",
      "   -------- ------------------------------- 1/5 [pyproj]\n",
      "   -------- ------------------------------- 1/5 [pyproj]\n",
      "   -------- ------------------------------- 1/5 [pyproj]\n",
      "   ---------------- ----------------------- 2/5 [pyogrio]\n",
      "   ---------------- ----------------------- 2/5 [pyogrio]\n",
      "   ------------------------ --------------- 3/5 [geopandas]\n",
      "   ------------------------ --------------- 3/5 [geopandas]\n",
      "   ------------------------ --------------- 3/5 [geopandas]\n",
      "   ------------------------ --------------- 3/5 [geopandas]\n",
      "   ------------------------ --------------- 3/5 [geopandas]\n",
      "   ------------------------ --------------- 3/5 [geopandas]\n",
      "   -------------------------------- ------- 4/5 [osmnx]\n",
      "   -------------------------------- ------- 4/5 [osmnx]\n",
      "   ---------------------------------------- 5/5 [osmnx]\n",
      "\n",
      "Successfully installed geopandas-1.1.1 osmnx-2.0.6 pyogrio-0.11.1 pyproj-3.7.2 shapely-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install osmnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2782946",
   "metadata": {},
   "source": [
    "# Data of a Square Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3acd29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\pyenv\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing path 1/600 (Point 0 -> Point 1)\n",
      "  Processing path 2/600 (Point 0 -> Point 2)\n",
      "  Processing path 3/600 (Point 0 -> Point 3)\n",
      "  Processing path 4/600 (Point 0 -> Point 4)\n",
      "  Processing path 5/600 (Point 0 -> Point 5)\n",
      "  Processing path 6/600 (Point 0 -> Point 6)\n",
      "  Processing path 7/600 (Point 0 -> Point 7)\n",
      "  Processing path 8/600 (Point 0 -> Point 8)\n",
      "  Processing path 9/600 (Point 0 -> Point 9)\n",
      "  Processing path 10/600 (Point 0 -> Point 10)\n",
      "  Processing path 11/600 (Point 0 -> Point 11)\n",
      "  Processing path 12/600 (Point 0 -> Point 12)\n",
      "  Processing path 13/600 (Point 0 -> Point 13)\n",
      "  Processing path 14/600 (Point 0 -> Point 14)\n",
      "  Processing path 15/600 (Point 0 -> Point 15)\n",
      "  Processing path 16/600 (Point 0 -> Point 16)\n",
      "  Processing path 17/600 (Point 0 -> Point 17)\n",
      "  Processing path 18/600 (Point 0 -> Point 18)\n",
      "  Processing path 19/600 (Point 0 -> Point 19)\n",
      "  Processing path 20/600 (Point 0 -> Point 20)\n",
      "  Processing path 21/600 (Point 0 -> Point 21)\n",
      "  Processing path 22/600 (Point 0 -> Point 22)\n",
      "  Processing path 23/600 (Point 0 -> Point 23)\n",
      "  Processing path 24/600 (Point 0 -> Point 24)\n",
      "  Processing path 25/600 (Point 1 -> Point 0)\n",
      "  Processing path 26/600 (Point 1 -> Point 2)\n",
      "  Processing path 27/600 (Point 1 -> Point 3)\n",
      "  Processing path 28/600 (Point 1 -> Point 4)\n",
      "  Processing path 29/600 (Point 1 -> Point 5)\n",
      "  Processing path 30/600 (Point 1 -> Point 6)\n",
      "  Processing path 31/600 (Point 1 -> Point 7)\n",
      "  Processing path 32/600 (Point 1 -> Point 8)\n",
      "  Processing path 33/600 (Point 1 -> Point 9)\n",
      "  Processing path 34/600 (Point 1 -> Point 10)\n",
      "  Processing path 35/600 (Point 1 -> Point 11)\n",
      "  Processing path 36/600 (Point 1 -> Point 12)\n",
      "  Processing path 37/600 (Point 1 -> Point 13)\n",
      "  Processing path 38/600 (Point 1 -> Point 14)\n",
      "  Processing path 39/600 (Point 1 -> Point 15)\n",
      "  Processing path 40/600 (Point 1 -> Point 16)\n",
      "  Processing path 41/600 (Point 1 -> Point 17)\n",
      "  Processing path 42/600 (Point 1 -> Point 18)\n",
      "  Processing path 43/600 (Point 1 -> Point 19)\n",
      "  Processing path 44/600 (Point 1 -> Point 20)\n",
      "  Processing path 45/600 (Point 1 -> Point 21)\n",
      "  Processing path 46/600 (Point 1 -> Point 22)\n",
      "  Processing path 47/600 (Point 1 -> Point 23)\n",
      "  Processing path 48/600 (Point 1 -> Point 24)\n",
      "  Processing path 49/600 (Point 2 -> Point 0)\n",
      "  Processing path 50/600 (Point 2 -> Point 1)\n",
      "  Processing path 51/600 (Point 2 -> Point 3)\n",
      "  Processing path 52/600 (Point 2 -> Point 4)\n",
      "  Processing path 53/600 (Point 2 -> Point 5)\n",
      "  Processing path 54/600 (Point 2 -> Point 6)\n",
      "  Processing path 55/600 (Point 2 -> Point 7)\n",
      "  Processing path 56/600 (Point 2 -> Point 8)\n",
      "  Processing path 57/600 (Point 2 -> Point 9)\n",
      "  Processing path 58/600 (Point 2 -> Point 10)\n",
      "  Processing path 59/600 (Point 2 -> Point 11)\n",
      "  Processing path 60/600 (Point 2 -> Point 12)\n",
      "  Processing path 61/600 (Point 2 -> Point 13)\n",
      "  Processing path 62/600 (Point 2 -> Point 14)\n",
      "  Processing path 63/600 (Point 2 -> Point 15)\n",
      "  Processing path 64/600 (Point 2 -> Point 16)\n",
      "  Processing path 65/600 (Point 2 -> Point 17)\n",
      "  Processing path 66/600 (Point 2 -> Point 18)\n",
      "  Processing path 67/600 (Point 2 -> Point 19)\n",
      "  Processing path 68/600 (Point 2 -> Point 20)\n",
      "  Processing path 69/600 (Point 2 -> Point 21)\n",
      "  Processing path 70/600 (Point 2 -> Point 22)\n",
      "  Processing path 71/600 (Point 2 -> Point 23)\n",
      "  Processing path 72/600 (Point 2 -> Point 24)\n",
      "  Processing path 73/600 (Point 3 -> Point 0)\n",
      "  Processing path 74/600 (Point 3 -> Point 1)\n",
      "  Processing path 75/600 (Point 3 -> Point 2)\n",
      "  Processing path 76/600 (Point 3 -> Point 4)\n",
      "  Processing path 77/600 (Point 3 -> Point 5)\n",
      "  Processing path 78/600 (Point 3 -> Point 6)\n",
      "  Processing path 79/600 (Point 3 -> Point 7)\n",
      "  Processing path 80/600 (Point 3 -> Point 8)\n",
      "  Processing path 81/600 (Point 3 -> Point 9)\n",
      "  Processing path 82/600 (Point 3 -> Point 10)\n",
      "  Processing path 83/600 (Point 3 -> Point 11)\n",
      "  Processing path 84/600 (Point 3 -> Point 12)\n",
      "  Processing path 85/600 (Point 3 -> Point 13)\n",
      "  Processing path 86/600 (Point 3 -> Point 14)\n",
      "  Processing path 87/600 (Point 3 -> Point 15)\n",
      "  Processing path 88/600 (Point 3 -> Point 16)\n",
      "  Processing path 89/600 (Point 3 -> Point 17)\n",
      "  Processing path 90/600 (Point 3 -> Point 18)\n",
      "  Processing path 91/600 (Point 3 -> Point 19)\n",
      "  Processing path 92/600 (Point 3 -> Point 20)\n",
      "  Processing path 93/600 (Point 3 -> Point 21)\n",
      "  Processing path 94/600 (Point 3 -> Point 22)\n",
      "  Processing path 95/600 (Point 3 -> Point 23)\n",
      "  Processing path 96/600 (Point 3 -> Point 24)\n",
      "  Processing path 97/600 (Point 4 -> Point 0)\n",
      "  Processing path 98/600 (Point 4 -> Point 1)\n",
      "  Processing path 99/600 (Point 4 -> Point 2)\n",
      "  Processing path 100/600 (Point 4 -> Point 3)\n",
      "  Processing path 101/600 (Point 4 -> Point 5)\n",
      "  Processing path 102/600 (Point 4 -> Point 6)\n",
      "  Processing path 103/600 (Point 4 -> Point 7)\n",
      "  Processing path 104/600 (Point 4 -> Point 8)\n",
      "  Processing path 105/600 (Point 4 -> Point 9)\n",
      "  Processing path 106/600 (Point 4 -> Point 10)\n",
      "  Processing path 107/600 (Point 4 -> Point 11)\n",
      "  Processing path 108/600 (Point 4 -> Point 12)\n",
      "  Processing path 109/600 (Point 4 -> Point 13)\n",
      "  Processing path 110/600 (Point 4 -> Point 14)\n",
      "  Processing path 111/600 (Point 4 -> Point 15)\n",
      "  Processing path 112/600 (Point 4 -> Point 16)\n",
      "  Processing path 113/600 (Point 4 -> Point 17)\n",
      "  Processing path 114/600 (Point 4 -> Point 18)\n",
      "  Processing path 115/600 (Point 4 -> Point 19)\n",
      "  Processing path 116/600 (Point 4 -> Point 20)\n",
      "  Processing path 117/600 (Point 4 -> Point 21)\n",
      "  Processing path 118/600 (Point 4 -> Point 22)\n",
      "  Processing path 119/600 (Point 4 -> Point 23)\n",
      "  Processing path 120/600 (Point 4 -> Point 24)\n",
      "  Processing path 121/600 (Point 5 -> Point 0)\n",
      "  Processing path 122/600 (Point 5 -> Point 1)\n",
      "  Processing path 123/600 (Point 5 -> Point 2)\n",
      "  Processing path 124/600 (Point 5 -> Point 3)\n",
      "  Processing path 125/600 (Point 5 -> Point 4)\n",
      "  Processing path 126/600 (Point 5 -> Point 6)\n",
      "  Processing path 127/600 (Point 5 -> Point 7)\n",
      "  Processing path 128/600 (Point 5 -> Point 8)\n",
      "  Processing path 129/600 (Point 5 -> Point 9)\n",
      "  Processing path 130/600 (Point 5 -> Point 10)\n",
      "  Processing path 131/600 (Point 5 -> Point 11)\n",
      "  Processing path 132/600 (Point 5 -> Point 12)\n",
      "  Processing path 133/600 (Point 5 -> Point 13)\n",
      "  Processing path 134/600 (Point 5 -> Point 14)\n",
      "  Processing path 135/600 (Point 5 -> Point 15)\n",
      "  Processing path 136/600 (Point 5 -> Point 16)\n",
      "  Processing path 137/600 (Point 5 -> Point 17)\n",
      "  Processing path 138/600 (Point 5 -> Point 18)\n",
      "  Processing path 139/600 (Point 5 -> Point 19)\n",
      "  Processing path 140/600 (Point 5 -> Point 20)\n",
      "  Processing path 141/600 (Point 5 -> Point 21)\n",
      "  Processing path 142/600 (Point 5 -> Point 22)\n",
      "  Processing path 143/600 (Point 5 -> Point 23)\n",
      "  Processing path 144/600 (Point 5 -> Point 24)\n",
      "  Processing path 145/600 (Point 6 -> Point 0)\n",
      "  Processing path 146/600 (Point 6 -> Point 1)\n",
      "  Processing path 147/600 (Point 6 -> Point 2)\n",
      "  Processing path 148/600 (Point 6 -> Point 3)\n",
      "  Processing path 149/600 (Point 6 -> Point 4)\n",
      "  Processing path 150/600 (Point 6 -> Point 5)\n",
      "  Processing path 151/600 (Point 6 -> Point 7)\n",
      "  Processing path 152/600 (Point 6 -> Point 8)\n",
      "  Processing path 153/600 (Point 6 -> Point 9)\n",
      "  Processing path 154/600 (Point 6 -> Point 10)\n",
      "  Processing path 155/600 (Point 6 -> Point 11)\n",
      "  Processing path 156/600 (Point 6 -> Point 12)\n",
      "  Processing path 157/600 (Point 6 -> Point 13)\n",
      "  Processing path 158/600 (Point 6 -> Point 14)\n",
      "  Processing path 159/600 (Point 6 -> Point 15)\n",
      "  Processing path 160/600 (Point 6 -> Point 16)\n",
      "  Processing path 161/600 (Point 6 -> Point 17)\n",
      "  Processing path 162/600 (Point 6 -> Point 18)\n",
      "  Processing path 163/600 (Point 6 -> Point 19)\n",
      "  Processing path 164/600 (Point 6 -> Point 20)\n",
      "  Processing path 165/600 (Point 6 -> Point 21)\n",
      "  Processing path 166/600 (Point 6 -> Point 22)\n",
      "  Processing path 167/600 (Point 6 -> Point 23)\n",
      "  Processing path 168/600 (Point 6 -> Point 24)\n",
      "  Processing path 169/600 (Point 7 -> Point 0)\n",
      "  Processing path 170/600 (Point 7 -> Point 1)\n",
      "  Processing path 171/600 (Point 7 -> Point 2)\n",
      "  Processing path 172/600 (Point 7 -> Point 3)\n",
      "  Processing path 173/600 (Point 7 -> Point 4)\n",
      "  Processing path 174/600 (Point 7 -> Point 5)\n",
      "  Processing path 175/600 (Point 7 -> Point 6)\n",
      "  Processing path 176/600 (Point 7 -> Point 8)\n",
      "  Processing path 177/600 (Point 7 -> Point 9)\n",
      "  Processing path 178/600 (Point 7 -> Point 10)\n",
      "  Processing path 179/600 (Point 7 -> Point 11)\n",
      "  Processing path 180/600 (Point 7 -> Point 12)\n",
      "  Processing path 181/600 (Point 7 -> Point 13)\n",
      "  Processing path 182/600 (Point 7 -> Point 14)\n",
      "  Processing path 183/600 (Point 7 -> Point 15)\n",
      "  Processing path 184/600 (Point 7 -> Point 16)\n",
      "  Processing path 185/600 (Point 7 -> Point 17)\n",
      "  Processing path 186/600 (Point 7 -> Point 18)\n",
      "  Processing path 187/600 (Point 7 -> Point 19)\n",
      "  Processing path 188/600 (Point 7 -> Point 20)\n",
      "  Processing path 189/600 (Point 7 -> Point 21)\n",
      "  Processing path 190/600 (Point 7 -> Point 22)\n",
      "  Processing path 191/600 (Point 7 -> Point 23)\n",
      "  Processing path 192/600 (Point 7 -> Point 24)\n",
      "  Processing path 193/600 (Point 8 -> Point 0)\n",
      "  Processing path 194/600 (Point 8 -> Point 1)\n",
      "  Processing path 195/600 (Point 8 -> Point 2)\n",
      "  Processing path 196/600 (Point 8 -> Point 3)\n",
      "  Processing path 197/600 (Point 8 -> Point 4)\n",
      "  Processing path 198/600 (Point 8 -> Point 5)\n",
      "  Processing path 199/600 (Point 8 -> Point 6)\n",
      "  Processing path 200/600 (Point 8 -> Point 7)\n",
      "  Processing path 201/600 (Point 8 -> Point 9)\n",
      "  Processing path 202/600 (Point 8 -> Point 10)\n",
      "  Processing path 203/600 (Point 8 -> Point 11)\n",
      "  Processing path 204/600 (Point 8 -> Point 12)\n",
      "  Processing path 205/600 (Point 8 -> Point 13)\n",
      "  Processing path 206/600 (Point 8 -> Point 14)\n",
      "  Processing path 207/600 (Point 8 -> Point 15)\n",
      "  Processing path 208/600 (Point 8 -> Point 16)\n",
      "  Processing path 209/600 (Point 8 -> Point 17)\n",
      "  Processing path 210/600 (Point 8 -> Point 18)\n",
      "  Processing path 211/600 (Point 8 -> Point 19)\n",
      "  Processing path 212/600 (Point 8 -> Point 20)\n",
      "  Processing path 213/600 (Point 8 -> Point 21)\n",
      "  Processing path 214/600 (Point 8 -> Point 22)\n",
      "  Processing path 215/600 (Point 8 -> Point 23)\n",
      "  Processing path 216/600 (Point 8 -> Point 24)\n",
      "  Processing path 217/600 (Point 9 -> Point 0)\n",
      "  Processing path 218/600 (Point 9 -> Point 1)\n",
      "  Processing path 219/600 (Point 9 -> Point 2)\n",
      "  Processing path 220/600 (Point 9 -> Point 3)\n",
      "  Processing path 221/600 (Point 9 -> Point 4)\n",
      "  Processing path 222/600 (Point 9 -> Point 5)\n",
      "  Processing path 223/600 (Point 9 -> Point 6)\n",
      "  Processing path 224/600 (Point 9 -> Point 7)\n",
      "  Processing path 225/600 (Point 9 -> Point 8)\n",
      "  Processing path 226/600 (Point 9 -> Point 10)\n",
      "  Processing path 227/600 (Point 9 -> Point 11)\n",
      "  Processing path 228/600 (Point 9 -> Point 12)\n",
      "  Processing path 229/600 (Point 9 -> Point 13)\n",
      "  Processing path 230/600 (Point 9 -> Point 14)\n",
      "  Processing path 231/600 (Point 9 -> Point 15)\n",
      "  Processing path 232/600 (Point 9 -> Point 16)\n",
      "  Processing path 233/600 (Point 9 -> Point 17)\n",
      "  Processing path 234/600 (Point 9 -> Point 18)\n",
      "  Processing path 235/600 (Point 9 -> Point 19)\n",
      "  Processing path 236/600 (Point 9 -> Point 20)\n",
      "  Processing path 237/600 (Point 9 -> Point 21)\n",
      "  Processing path 238/600 (Point 9 -> Point 22)\n",
      "  Processing path 239/600 (Point 9 -> Point 23)\n",
      "  Processing path 240/600 (Point 9 -> Point 24)\n",
      "  Processing path 241/600 (Point 10 -> Point 0)\n",
      "  Processing path 242/600 (Point 10 -> Point 1)\n",
      "  Processing path 243/600 (Point 10 -> Point 2)\n",
      "  Processing path 244/600 (Point 10 -> Point 3)\n",
      "  Processing path 245/600 (Point 10 -> Point 4)\n",
      "  Processing path 246/600 (Point 10 -> Point 5)\n",
      "  Processing path 247/600 (Point 10 -> Point 6)\n",
      "  Processing path 248/600 (Point 10 -> Point 7)\n",
      "  Processing path 249/600 (Point 10 -> Point 8)\n",
      "  Processing path 250/600 (Point 10 -> Point 9)\n",
      "  Processing path 251/600 (Point 10 -> Point 11)\n",
      "  Processing path 252/600 (Point 10 -> Point 12)\n",
      "  Processing path 253/600 (Point 10 -> Point 13)\n",
      "  Processing path 254/600 (Point 10 -> Point 14)\n",
      "  Processing path 255/600 (Point 10 -> Point 15)\n",
      "  Processing path 256/600 (Point 10 -> Point 16)\n",
      "  Processing path 257/600 (Point 10 -> Point 17)\n",
      "  Processing path 258/600 (Point 10 -> Point 18)\n",
      "  Processing path 259/600 (Point 10 -> Point 19)\n",
      "  Processing path 260/600 (Point 10 -> Point 20)\n",
      "  Processing path 261/600 (Point 10 -> Point 21)\n",
      "  Processing path 262/600 (Point 10 -> Point 22)\n",
      "  Processing path 263/600 (Point 10 -> Point 23)\n",
      "  Processing path 264/600 (Point 10 -> Point 24)\n",
      "  Processing path 265/600 (Point 11 -> Point 0)\n",
      "  Processing path 266/600 (Point 11 -> Point 1)\n",
      "  Processing path 267/600 (Point 11 -> Point 2)\n",
      "  Processing path 268/600 (Point 11 -> Point 3)\n",
      "  Processing path 269/600 (Point 11 -> Point 4)\n",
      "  Processing path 270/600 (Point 11 -> Point 5)\n",
      "  Processing path 271/600 (Point 11 -> Point 6)\n",
      "  Processing path 272/600 (Point 11 -> Point 7)\n",
      "  Processing path 273/600 (Point 11 -> Point 8)\n",
      "  Processing path 274/600 (Point 11 -> Point 9)\n",
      "  Processing path 275/600 (Point 11 -> Point 10)\n",
      "  Processing path 276/600 (Point 11 -> Point 12)\n",
      "  Processing path 277/600 (Point 11 -> Point 13)\n",
      "  Processing path 278/600 (Point 11 -> Point 14)\n",
      "  Processing path 279/600 (Point 11 -> Point 15)\n",
      "  Processing path 280/600 (Point 11 -> Point 16)\n",
      "  Processing path 281/600 (Point 11 -> Point 17)\n",
      "  Processing path 282/600 (Point 11 -> Point 18)\n",
      "  Processing path 283/600 (Point 11 -> Point 19)\n",
      "  Processing path 284/600 (Point 11 -> Point 20)\n",
      "  Processing path 285/600 (Point 11 -> Point 21)\n",
      "  Processing path 286/600 (Point 11 -> Point 22)\n",
      "  Processing path 287/600 (Point 11 -> Point 23)\n",
      "  Processing path 288/600 (Point 11 -> Point 24)\n",
      "  Processing path 289/600 (Point 12 -> Point 0)\n",
      "  Processing path 290/600 (Point 12 -> Point 1)\n",
      "  Processing path 291/600 (Point 12 -> Point 2)\n",
      "  Processing path 292/600 (Point 12 -> Point 3)\n",
      "  Processing path 293/600 (Point 12 -> Point 4)\n",
      "  Processing path 294/600 (Point 12 -> Point 5)\n",
      "  Processing path 295/600 (Point 12 -> Point 6)\n",
      "  Processing path 296/600 (Point 12 -> Point 7)\n",
      "  Processing path 297/600 (Point 12 -> Point 8)\n",
      "  Processing path 298/600 (Point 12 -> Point 9)\n",
      "  Processing path 299/600 (Point 12 -> Point 10)\n",
      "  Processing path 300/600 (Point 12 -> Point 11)\n",
      "  Processing path 301/600 (Point 12 -> Point 13)\n",
      "  Processing path 302/600 (Point 12 -> Point 14)\n",
      "  Processing path 303/600 (Point 12 -> Point 15)\n",
      "  Processing path 304/600 (Point 12 -> Point 16)\n",
      "  Processing path 305/600 (Point 12 -> Point 17)\n",
      "  Processing path 306/600 (Point 12 -> Point 18)\n",
      "  Processing path 307/600 (Point 12 -> Point 19)\n",
      "  Processing path 308/600 (Point 12 -> Point 20)\n",
      "  Processing path 309/600 (Point 12 -> Point 21)\n",
      "  Processing path 310/600 (Point 12 -> Point 22)\n",
      "  Processing path 311/600 (Point 12 -> Point 23)\n",
      "  Processing path 312/600 (Point 12 -> Point 24)\n",
      "  Processing path 313/600 (Point 13 -> Point 0)\n",
      "  Processing path 314/600 (Point 13 -> Point 1)\n",
      "  Processing path 315/600 (Point 13 -> Point 2)\n",
      "  Processing path 316/600 (Point 13 -> Point 3)\n",
      "  Processing path 317/600 (Point 13 -> Point 4)\n",
      "  Processing path 318/600 (Point 13 -> Point 5)\n",
      "  Processing path 319/600 (Point 13 -> Point 6)\n",
      "  Processing path 320/600 (Point 13 -> Point 7)\n",
      "  Processing path 321/600 (Point 13 -> Point 8)\n",
      "  Processing path 322/600 (Point 13 -> Point 9)\n",
      "  Processing path 323/600 (Point 13 -> Point 10)\n",
      "  Processing path 324/600 (Point 13 -> Point 11)\n",
      "  Processing path 325/600 (Point 13 -> Point 12)\n",
      "  Processing path 326/600 (Point 13 -> Point 14)\n",
      "  Processing path 327/600 (Point 13 -> Point 15)\n",
      "  Processing path 328/600 (Point 13 -> Point 16)\n",
      "  Processing path 329/600 (Point 13 -> Point 17)\n",
      "  Processing path 330/600 (Point 13 -> Point 18)\n",
      "  Processing path 331/600 (Point 13 -> Point 19)\n",
      "  Processing path 332/600 (Point 13 -> Point 20)\n",
      "  Processing path 333/600 (Point 13 -> Point 21)\n",
      "  Processing path 334/600 (Point 13 -> Point 22)\n",
      "  Processing path 335/600 (Point 13 -> Point 23)\n",
      "  Processing path 336/600 (Point 13 -> Point 24)\n",
      "  Processing path 337/600 (Point 14 -> Point 0)\n",
      "  Processing path 338/600 (Point 14 -> Point 1)\n",
      "  Processing path 339/600 (Point 14 -> Point 2)\n",
      "  Processing path 340/600 (Point 14 -> Point 3)\n",
      "  Processing path 341/600 (Point 14 -> Point 4)\n",
      "  Processing path 342/600 (Point 14 -> Point 5)\n",
      "  Processing path 343/600 (Point 14 -> Point 6)\n",
      "  Processing path 344/600 (Point 14 -> Point 7)\n",
      "  Processing path 345/600 (Point 14 -> Point 8)\n",
      "  Processing path 346/600 (Point 14 -> Point 9)\n",
      "  Processing path 347/600 (Point 14 -> Point 10)\n",
      "  Processing path 348/600 (Point 14 -> Point 11)\n",
      "  Processing path 349/600 (Point 14 -> Point 12)\n",
      "  Processing path 350/600 (Point 14 -> Point 13)\n",
      "  Processing path 351/600 (Point 14 -> Point 15)\n",
      "  Processing path 352/600 (Point 14 -> Point 16)\n",
      "  Processing path 353/600 (Point 14 -> Point 17)\n",
      "  Processing path 354/600 (Point 14 -> Point 18)\n",
      "  Processing path 355/600 (Point 14 -> Point 19)\n",
      "  Processing path 356/600 (Point 14 -> Point 20)\n",
      "  Processing path 357/600 (Point 14 -> Point 21)\n",
      "  Processing path 358/600 (Point 14 -> Point 22)\n",
      "  Processing path 359/600 (Point 14 -> Point 23)\n",
      "  Processing path 360/600 (Point 14 -> Point 24)\n",
      "  Processing path 361/600 (Point 15 -> Point 0)\n",
      "  Processing path 362/600 (Point 15 -> Point 1)\n",
      "  Processing path 363/600 (Point 15 -> Point 2)\n",
      "  Processing path 364/600 (Point 15 -> Point 3)\n",
      "  Processing path 365/600 (Point 15 -> Point 4)\n",
      "  Processing path 366/600 (Point 15 -> Point 5)\n",
      "  Processing path 367/600 (Point 15 -> Point 6)\n",
      "  Processing path 368/600 (Point 15 -> Point 7)\n",
      "  Processing path 369/600 (Point 15 -> Point 8)\n",
      "  Processing path 370/600 (Point 15 -> Point 9)\n",
      "  Processing path 371/600 (Point 15 -> Point 10)\n",
      "  Processing path 372/600 (Point 15 -> Point 11)\n",
      "  Processing path 373/600 (Point 15 -> Point 12)\n",
      "  Processing path 374/600 (Point 15 -> Point 13)\n",
      "  Processing path 375/600 (Point 15 -> Point 14)\n",
      "  Processing path 376/600 (Point 15 -> Point 16)\n",
      "  Processing path 377/600 (Point 15 -> Point 17)\n",
      "  Processing path 378/600 (Point 15 -> Point 18)\n",
      "  Processing path 379/600 (Point 15 -> Point 19)\n",
      "  Processing path 380/600 (Point 15 -> Point 20)\n",
      "  Processing path 381/600 (Point 15 -> Point 21)\n",
      "  Processing path 382/600 (Point 15 -> Point 22)\n",
      "  Processing path 383/600 (Point 15 -> Point 23)\n",
      "  Processing path 384/600 (Point 15 -> Point 24)\n",
      "  Processing path 385/600 (Point 16 -> Point 0)\n",
      "  Processing path 386/600 (Point 16 -> Point 1)\n",
      "  Processing path 387/600 (Point 16 -> Point 2)\n",
      "  Processing path 388/600 (Point 16 -> Point 3)\n",
      "  Processing path 389/600 (Point 16 -> Point 4)\n",
      "  Processing path 390/600 (Point 16 -> Point 5)\n",
      "  Processing path 391/600 (Point 16 -> Point 6)\n",
      "  Processing path 392/600 (Point 16 -> Point 7)\n",
      "  Processing path 393/600 (Point 16 -> Point 8)\n",
      "  Processing path 394/600 (Point 16 -> Point 9)\n",
      "  Processing path 395/600 (Point 16 -> Point 10)\n",
      "  Processing path 396/600 (Point 16 -> Point 11)\n",
      "  Processing path 397/600 (Point 16 -> Point 12)\n",
      "  Processing path 398/600 (Point 16 -> Point 13)\n",
      "  Processing path 399/600 (Point 16 -> Point 14)\n",
      "  Processing path 400/600 (Point 16 -> Point 15)\n",
      "  Processing path 401/600 (Point 16 -> Point 17)\n",
      "  Processing path 402/600 (Point 16 -> Point 18)\n",
      "  Processing path 403/600 (Point 16 -> Point 19)\n",
      "  Processing path 404/600 (Point 16 -> Point 20)\n",
      "  Processing path 405/600 (Point 16 -> Point 21)\n",
      "  Processing path 406/600 (Point 16 -> Point 22)\n",
      "  Processing path 407/600 (Point 16 -> Point 23)\n",
      "  Processing path 408/600 (Point 16 -> Point 24)\n",
      "  Processing path 409/600 (Point 17 -> Point 0)\n",
      "  Processing path 410/600 (Point 17 -> Point 1)\n",
      "  Processing path 411/600 (Point 17 -> Point 2)\n",
      "  Processing path 412/600 (Point 17 -> Point 3)\n",
      "  Processing path 413/600 (Point 17 -> Point 4)\n",
      "  Processing path 414/600 (Point 17 -> Point 5)\n",
      "  Processing path 415/600 (Point 17 -> Point 6)\n",
      "  Processing path 416/600 (Point 17 -> Point 7)\n",
      "  Processing path 417/600 (Point 17 -> Point 8)\n",
      "  Processing path 418/600 (Point 17 -> Point 9)\n",
      "  Processing path 419/600 (Point 17 -> Point 10)\n",
      "  Processing path 420/600 (Point 17 -> Point 11)\n",
      "  Processing path 421/600 (Point 17 -> Point 12)\n",
      "  Processing path 422/600 (Point 17 -> Point 13)\n",
      "  Processing path 423/600 (Point 17 -> Point 14)\n",
      "  Processing path 424/600 (Point 17 -> Point 15)\n",
      "  Processing path 425/600 (Point 17 -> Point 16)\n",
      "  Processing path 426/600 (Point 17 -> Point 18)\n",
      "  Processing path 427/600 (Point 17 -> Point 19)\n",
      "  Processing path 428/600 (Point 17 -> Point 20)\n",
      "  Processing path 429/600 (Point 17 -> Point 21)\n",
      "  Processing path 430/600 (Point 17 -> Point 22)\n",
      "  Processing path 431/600 (Point 17 -> Point 23)\n",
      "  Processing path 432/600 (Point 17 -> Point 24)\n",
      "  Processing path 433/600 (Point 18 -> Point 0)\n",
      "  Processing path 434/600 (Point 18 -> Point 1)\n",
      "  Processing path 435/600 (Point 18 -> Point 2)\n",
      "  Processing path 436/600 (Point 18 -> Point 3)\n",
      "  Processing path 437/600 (Point 18 -> Point 4)\n",
      "  Processing path 438/600 (Point 18 -> Point 5)\n",
      "  Processing path 439/600 (Point 18 -> Point 6)\n",
      "  Processing path 440/600 (Point 18 -> Point 7)\n",
      "  Processing path 441/600 (Point 18 -> Point 8)\n",
      "  Processing path 442/600 (Point 18 -> Point 9)\n",
      "  Processing path 443/600 (Point 18 -> Point 10)\n",
      "  Processing path 444/600 (Point 18 -> Point 11)\n",
      "  Processing path 445/600 (Point 18 -> Point 12)\n",
      "  Processing path 446/600 (Point 18 -> Point 13)\n",
      "  Processing path 447/600 (Point 18 -> Point 14)\n",
      "  Processing path 448/600 (Point 18 -> Point 15)\n",
      "  Processing path 449/600 (Point 18 -> Point 16)\n",
      "  Processing path 450/600 (Point 18 -> Point 17)\n",
      "  Processing path 451/600 (Point 18 -> Point 19)\n",
      "  Processing path 452/600 (Point 18 -> Point 20)\n",
      "  Processing path 453/600 (Point 18 -> Point 21)\n",
      "  Processing path 454/600 (Point 18 -> Point 22)\n",
      "  Processing path 455/600 (Point 18 -> Point 23)\n",
      "  Processing path 456/600 (Point 18 -> Point 24)\n",
      "  Processing path 457/600 (Point 19 -> Point 0)\n",
      "  Processing path 458/600 (Point 19 -> Point 1)\n",
      "  Processing path 459/600 (Point 19 -> Point 2)\n",
      "  Processing path 460/600 (Point 19 -> Point 3)\n",
      "  Processing path 461/600 (Point 19 -> Point 4)\n",
      "  Processing path 462/600 (Point 19 -> Point 5)\n",
      "  Processing path 463/600 (Point 19 -> Point 6)\n",
      "  Processing path 464/600 (Point 19 -> Point 7)\n",
      "  Processing path 465/600 (Point 19 -> Point 8)\n",
      "  Processing path 466/600 (Point 19 -> Point 9)\n",
      "  Processing path 467/600 (Point 19 -> Point 10)\n",
      "  Processing path 468/600 (Point 19 -> Point 11)\n",
      "  Processing path 469/600 (Point 19 -> Point 12)\n",
      "  Processing path 470/600 (Point 19 -> Point 13)\n",
      "  Processing path 471/600 (Point 19 -> Point 14)\n",
      "  Processing path 472/600 (Point 19 -> Point 15)\n",
      "  Processing path 473/600 (Point 19 -> Point 16)\n",
      "  Processing path 474/600 (Point 19 -> Point 17)\n",
      "  Processing path 475/600 (Point 19 -> Point 18)\n",
      "  Processing path 476/600 (Point 19 -> Point 20)\n",
      "  Processing path 477/600 (Point 19 -> Point 21)\n",
      "  Processing path 478/600 (Point 19 -> Point 22)\n",
      "  Processing path 479/600 (Point 19 -> Point 23)\n",
      "  Processing path 480/600 (Point 19 -> Point 24)\n",
      "  Processing path 481/600 (Point 20 -> Point 0)\n",
      "  Processing path 482/600 (Point 20 -> Point 1)\n",
      "  Processing path 483/600 (Point 20 -> Point 2)\n",
      "  Processing path 484/600 (Point 20 -> Point 3)\n",
      "  Processing path 485/600 (Point 20 -> Point 4)\n",
      "  Processing path 486/600 (Point 20 -> Point 5)\n",
      "  Processing path 487/600 (Point 20 -> Point 6)\n",
      "  Processing path 488/600 (Point 20 -> Point 7)\n",
      "  Processing path 489/600 (Point 20 -> Point 8)\n",
      "  Processing path 490/600 (Point 20 -> Point 9)\n",
      "  Processing path 491/600 (Point 20 -> Point 10)\n",
      "  Processing path 492/600 (Point 20 -> Point 11)\n",
      "  Processing path 493/600 (Point 20 -> Point 12)\n",
      "  Processing path 494/600 (Point 20 -> Point 13)\n",
      "  Processing path 495/600 (Point 20 -> Point 14)\n",
      "  Processing path 496/600 (Point 20 -> Point 15)\n",
      "  Processing path 497/600 (Point 20 -> Point 16)\n",
      "  Processing path 498/600 (Point 20 -> Point 17)\n",
      "  Processing path 499/600 (Point 20 -> Point 18)\n",
      "  Processing path 500/600 (Point 20 -> Point 19)\n",
      "  Processing path 501/600 (Point 20 -> Point 21)\n",
      "  Processing path 502/600 (Point 20 -> Point 22)\n",
      "  Processing path 503/600 (Point 20 -> Point 23)\n",
      "  Processing path 504/600 (Point 20 -> Point 24)\n",
      "  Processing path 505/600 (Point 21 -> Point 0)\n",
      "  Processing path 506/600 (Point 21 -> Point 1)\n",
      "  Processing path 507/600 (Point 21 -> Point 2)\n",
      "  Processing path 508/600 (Point 21 -> Point 3)\n",
      "  Processing path 509/600 (Point 21 -> Point 4)\n",
      "  Processing path 510/600 (Point 21 -> Point 5)\n",
      "  Processing path 511/600 (Point 21 -> Point 6)\n",
      "  Processing path 512/600 (Point 21 -> Point 7)\n",
      "  Processing path 513/600 (Point 21 -> Point 8)\n",
      "  Processing path 514/600 (Point 21 -> Point 9)\n",
      "  Processing path 515/600 (Point 21 -> Point 10)\n",
      "  Processing path 516/600 (Point 21 -> Point 11)\n",
      "  Processing path 517/600 (Point 21 -> Point 12)\n",
      "  Processing path 518/600 (Point 21 -> Point 13)\n",
      "  Processing path 519/600 (Point 21 -> Point 14)\n",
      "  Processing path 520/600 (Point 21 -> Point 15)\n",
      "  Processing path 521/600 (Point 21 -> Point 16)\n",
      "  Processing path 522/600 (Point 21 -> Point 17)\n",
      "  Processing path 523/600 (Point 21 -> Point 18)\n",
      "  Processing path 524/600 (Point 21 -> Point 19)\n",
      "  Processing path 525/600 (Point 21 -> Point 20)\n",
      "  Processing path 526/600 (Point 21 -> Point 22)\n",
      "  Processing path 527/600 (Point 21 -> Point 23)\n",
      "  Processing path 528/600 (Point 21 -> Point 24)\n",
      "  Processing path 529/600 (Point 22 -> Point 0)\n",
      "  Processing path 530/600 (Point 22 -> Point 1)\n",
      "  Processing path 531/600 (Point 22 -> Point 2)\n",
      "  Processing path 532/600 (Point 22 -> Point 3)\n",
      "  Processing path 533/600 (Point 22 -> Point 4)\n",
      "  Processing path 534/600 (Point 22 -> Point 5)\n",
      "  Processing path 535/600 (Point 22 -> Point 6)\n",
      "  Processing path 536/600 (Point 22 -> Point 7)\n",
      "  Processing path 537/600 (Point 22 -> Point 8)\n",
      "  Processing path 538/600 (Point 22 -> Point 9)\n",
      "  Processing path 539/600 (Point 22 -> Point 10)\n",
      "  Processing path 540/600 (Point 22 -> Point 11)\n",
      "  Processing path 541/600 (Point 22 -> Point 12)\n",
      "  Processing path 542/600 (Point 22 -> Point 13)\n",
      "  Processing path 543/600 (Point 22 -> Point 14)\n",
      "  Processing path 544/600 (Point 22 -> Point 15)\n",
      "  Processing path 545/600 (Point 22 -> Point 16)\n",
      "  Processing path 546/600 (Point 22 -> Point 17)\n",
      "  Processing path 547/600 (Point 22 -> Point 18)\n",
      "  Processing path 548/600 (Point 22 -> Point 19)\n",
      "  Processing path 549/600 (Point 22 -> Point 20)\n",
      "  Processing path 550/600 (Point 22 -> Point 21)\n",
      "  Processing path 551/600 (Point 22 -> Point 23)\n",
      "  Processing path 552/600 (Point 22 -> Point 24)\n",
      "  Processing path 553/600 (Point 23 -> Point 0)\n",
      "  Processing path 554/600 (Point 23 -> Point 1)\n",
      "  Processing path 555/600 (Point 23 -> Point 2)\n",
      "  Processing path 556/600 (Point 23 -> Point 3)\n",
      "  Processing path 557/600 (Point 23 -> Point 4)\n",
      "  Processing path 558/600 (Point 23 -> Point 5)\n",
      "  Processing path 559/600 (Point 23 -> Point 6)\n",
      "  Processing path 560/600 (Point 23 -> Point 7)\n",
      "  Processing path 561/600 (Point 23 -> Point 8)\n",
      "  Processing path 562/600 (Point 23 -> Point 9)\n",
      "  Processing path 563/600 (Point 23 -> Point 10)\n",
      "  Processing path 564/600 (Point 23 -> Point 11)\n",
      "  Processing path 565/600 (Point 23 -> Point 12)\n",
      "  Processing path 566/600 (Point 23 -> Point 13)\n",
      "  Processing path 567/600 (Point 23 -> Point 14)\n",
      "  Processing path 568/600 (Point 23 -> Point 15)\n",
      "  Processing path 569/600 (Point 23 -> Point 16)\n",
      "  Processing path 570/600 (Point 23 -> Point 17)\n",
      "  Processing path 571/600 (Point 23 -> Point 18)\n",
      "  Processing path 572/600 (Point 23 -> Point 19)\n",
      "  Processing path 573/600 (Point 23 -> Point 20)\n",
      "  Processing path 574/600 (Point 23 -> Point 21)\n",
      "  Processing path 575/600 (Point 23 -> Point 22)\n",
      "  Processing path 576/600 (Point 23 -> Point 24)\n",
      "  Processing path 577/600 (Point 24 -> Point 0)\n",
      "  Processing path 578/600 (Point 24 -> Point 1)\n",
      "  Processing path 579/600 (Point 24 -> Point 2)\n",
      "  Processing path 580/600 (Point 24 -> Point 3)\n",
      "  Processing path 581/600 (Point 24 -> Point 4)\n",
      "  Processing path 582/600 (Point 24 -> Point 5)\n",
      "  Processing path 583/600 (Point 24 -> Point 6)\n",
      "  Processing path 584/600 (Point 24 -> Point 7)\n",
      "  Processing path 585/600 (Point 24 -> Point 8)\n",
      "  Processing path 586/600 (Point 24 -> Point 9)\n",
      "  Processing path 587/600 (Point 24 -> Point 10)\n",
      "  Processing path 588/600 (Point 24 -> Point 11)\n",
      "  Processing path 589/600 (Point 24 -> Point 12)\n",
      "  Processing path 590/600 (Point 24 -> Point 13)\n",
      "  Processing path 591/600 (Point 24 -> Point 14)\n",
      "  Processing path 592/600 (Point 24 -> Point 15)\n",
      "  Processing path 593/600 (Point 24 -> Point 16)\n",
      "  Processing path 594/600 (Point 24 -> Point 17)\n",
      "  Processing path 595/600 (Point 24 -> Point 18)\n",
      "  Processing path 596/600 (Point 24 -> Point 19)\n",
      "  Processing path 597/600 (Point 24 -> Point 20)\n",
      "  Processing path 598/600 (Point 24 -> Point 21)\n",
      "  Processing path 599/600 (Point 24 -> Point 22)\n",
      "  Processing path 600/600 (Point 24 -> Point 23)\n",
      "\n",
      " Successfully generated detailed path data!\n",
      "'traffic_report_2025-10-14_11-30-49.csv' is now ready for Tableau.\n"
     ]
    }
   ],
   "source": [
    "import googlemaps\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import osmnx as ox\n",
    "import random\n",
    "\n",
    "# --- Configuration ---\n",
    "API_KEY = \"Add your google traffic api key\"\n",
    "\n",
    "# Define the area and grid size as before\n",
    "AREA_BOUNDS = {\n",
    "    \"sw\": (28.542092, 77.025868),  # South-West corner (lat, lon)\n",
    "    \"ne\": (28.741011, 77.307083)  # North-East corner\n",
    "}\n",
    "GRID_SIZE_X = 5\n",
    "GRID_SIZE_Y = 5\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"traffic_report_{timestamp}.csv\"\n",
    "OUTPUT_FILENAME = filename\n",
    "\n",
    "# --- Main Script ---\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "\n",
    "def generate_grid_points(bounds, num_x, num_y):\n",
    "    lats = np.linspace(bounds[\"sw\"][0], bounds[\"ne\"][0], num_y)\n",
    "    lons = np.linspace(bounds[\"sw\"][1], bounds[\"ne\"][1], num_x)\n",
    "    return [(lat, lon) for lat in lats for lon in lons]\n",
    "\n",
    "grid_points = generate_grid_points(AREA_BOUNDS, GRID_SIZE_X, GRID_SIZE_Y)\n",
    "\n",
    "all_path_points = []\n",
    "total_paths = (GRID_SIZE_X * GRID_SIZE_Y) ** 2 - (GRID_SIZE_X * GRID_SIZE_Y)\n",
    "path_counter = 0\n",
    "\n",
    "\n",
    "for i, origin in enumerate(grid_points):\n",
    "    for j, destination in enumerate(grid_points):\n",
    "        if i == j:\n",
    "            continue\n",
    "        \n",
    "        path_counter += 1\n",
    "        print(f\"  Processing path {path_counter}/{total_paths} (Point {i} -> Point {j})\")\n",
    "\n",
    "     \n",
    "        # Request directions for this specific pair\n",
    "        directions_result = gmaps.directions(origin,\n",
    "                                                destination,\n",
    "                                                mode=\"driving\",\n",
    "                                                departure_time=datetime.now())\n",
    "\n",
    "        if not directions_result:\n",
    "            continue\n",
    "\n",
    "        # --- Extract Key Information ---\n",
    "        route = directions_result[0] # Use the primary recommended route\n",
    "        leg = route['legs'][0]\n",
    "        \n",
    "        # Calculate congestion factor for this specific path\n",
    "        duration_val = leg['duration']['value']\n",
    "        duration_traffic_val = leg.get('duration_in_traffic', {}).get('value', duration_val)\n",
    "        congestion_factor = duration_traffic_val / duration_val if duration_val > 0 else 1\n",
    "\n",
    "        # --- Decode the Polyline to get actual road coordinates ---\n",
    "        encoded_polyline = route['overview_polyline']['points']\n",
    "        decoded_path = googlemaps.convert.decode_polyline(encoded_polyline)\n",
    "\n",
    "        # Create a unique ID for this path\n",
    "        path_id = f\"Point {i} -> Point {j}\"\n",
    "        \n",
    "        # For each coordinate in the decoded path, create a row for Tableau\n",
    "        for order, point in enumerate(decoded_path):\n",
    "            all_path_points.append({\n",
    "                'Path_ID': path_id,\n",
    "                'Point_Order': order + 1,\n",
    "                'Latitude': point['lat'],\n",
    "                'Longitude': point['lng'],\n",
    "                'Congestion_Factor': round(congestion_factor, 2),\n",
    "                'Distance_Text': leg['distance']['text'],\n",
    "                'Duration_in_Traffic_Text': leg.get('duration_in_traffic', {}).get('text', 'N/A')\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert the final list into a DataFrame\n",
    "tableau_df = pd.DataFrame(all_path_points)\n",
    "\n",
    "# Save the detailed path data to a new CSV file\n",
    "tableau_df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "\n",
    "print(f\"\\n Successfully generated detailed path data!\")\n",
    "print(f\"'{OUTPUT_FILENAME}' is now ready for Tableau.\")\n",
    "\n",
    "# --- Configuration ---\n",
    "API_KEY = \"Add your google traffic api key\"\n",
    "API_KEY = \"Enter API key here \"\n",
    "\n",
    "# Define the area and grid size as before\n",
    "AREA_BOUNDS = {\n",
    "    \"sw\": (28.341944, 76.811111),  # South-West corner (lat, lon)\n",
    "    \"ne\": (28.928889, 77.473056)   # North-East corner\n",
    "}\n",
    "GRID_SIZE_X = 5\n",
    "GRID_SIZE_Y = 5\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"traffic_report_{timestamp}.csv\"\n",
    "OUTPUT_FILENAME = filename\n",
    "\n",
    "# --- Main Script ---\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "\n",
    "def generate_grid_points(bounds, num_x, num_y):\n",
    "    lats = np.linspace(bounds[\"sw\"][0], bounds[\"ne\"][0], num_y)\n",
    "    lons = np.linspace(bounds[\"sw\"][1], bounds[\"ne\"][1], num_x)\n",
    "    return [(lat, lon) for lat in lats for lon in lons]\n",
    "\n",
    "grid_points = generate_grid_points(AREA_BOUNDS, GRID_SIZE_X, GRID_SIZE_Y)\n",
    "\n",
    "all_path_points = []\n",
    "total_paths = (GRID_SIZE_X * GRID_SIZE_Y) ** 2 - (GRID_SIZE_X * GRID_SIZE_Y)\n",
    "path_counter = 0\n",
    "\n",
    "\n",
    "for i, origin in enumerate(grid_points):\n",
    "    for j, destination in enumerate(grid_points):\n",
    "        if i == j:\n",
    "            continue\n",
    "        \n",
    "        path_counter += 1\n",
    "        print(f\"  Processing path {path_counter}/{total_paths} (Point {i} -> Point {j})\")\n",
    "\n",
    "     \n",
    "        # Request directions for this specific pair\n",
    "        directions_result = gmaps.directions(origin,\n",
    "                                                destination,\n",
    "                                                mode=\"driving\",\n",
    "                                                departure_time=datetime.now())\n",
    "\n",
    "        if not directions_result:\n",
    "            continue\n",
    "\n",
    "        # --- Extract Key Information ---\n",
    "        route = directions_result[0] # Use the primary recommended route\n",
    "        leg = route['legs'][0]\n",
    "        \n",
    "        # Calculate congestion factor for this specific path\n",
    "        duration_val = leg['duration']['value']\n",
    "        duration_traffic_val = leg.get('duration_in_traffic', {}).get('value', duration_val)\n",
    "        congestion_factor = duration_traffic_val / duration_val if duration_val > 0 else 1\n",
    "\n",
    "        # --- Decode the Polyline to get actual road coordinates ---\n",
    "        encoded_polyline = route['overview_polyline']['points']\n",
    "        decoded_path = googlemaps.convert.decode_polyline(encoded_polyline)\n",
    "\n",
    "        # Create a unique ID for this path\n",
    "        path_id = f\"Point {i} -> Point {j}\"\n",
    "        \n",
    "        # For each coordinate in the decoded path, create a row for Tableau\n",
    "        for order, point in enumerate(decoded_path):\n",
    "            all_path_points.append({\n",
    "                'Path_ID': path_id,\n",
    "                'Point_Order': order + 1,\n",
    "                'Latitude': point['lat'],\n",
    "                'Longitude': point['lng'],\n",
    "                'Congestion_Factor': round(congestion_factor, 2),\n",
    "                'Distance_Text': leg['distance']['text'],\n",
    "                'Duration_in_Traffic_Text': leg.get('duration_in_traffic', {}).get('text', 'N/A')\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert the final list into a DataFrame\n",
    "tableau_df = pd.DataFrame(all_path_points)\n",
    "\n",
    "# Save the detailed path data to a new CSV file\n",
    "tableau_df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "\n",
    "print(f\"\\n Successfully generated detailed path data!\")\n",
    "print(f\"'{OUTPUT_FILENAME}' is now ready for Tableau.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8263eaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path_ID</th>\n",
       "      <th>Point_Order</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Congestion_Factor</th>\n",
       "      <th>Distance_Text</th>\n",
       "      <th>Duration_in_Traffic_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Point 0 -&gt; Point 1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.48000</td>\n",
       "      <td>76.93017</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0 km</td>\n",
       "      <td>9 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Point 0 -&gt; Point 1</td>\n",
       "      <td>2</td>\n",
       "      <td>28.47953</td>\n",
       "      <td>76.93015</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0 km</td>\n",
       "      <td>9 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Point 0 -&gt; Point 1</td>\n",
       "      <td>3</td>\n",
       "      <td>28.47958</td>\n",
       "      <td>76.93033</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0 km</td>\n",
       "      <td>9 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Point 0 -&gt; Point 1</td>\n",
       "      <td>4</td>\n",
       "      <td>28.47974</td>\n",
       "      <td>76.93075</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0 km</td>\n",
       "      <td>9 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Point 0 -&gt; Point 1</td>\n",
       "      <td>5</td>\n",
       "      <td>28.47982</td>\n",
       "      <td>76.93090</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0 km</td>\n",
       "      <td>9 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8848</th>\n",
       "      <td>Point 8 -&gt; Point 7</td>\n",
       "      <td>49</td>\n",
       "      <td>28.52003</td>\n",
       "      <td>76.94858</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.2 km</td>\n",
       "      <td>9 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8849</th>\n",
       "      <td>Point 8 -&gt; Point 7</td>\n",
       "      <td>50</td>\n",
       "      <td>28.51917</td>\n",
       "      <td>76.94813</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.2 km</td>\n",
       "      <td>9 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8850</th>\n",
       "      <td>Point 8 -&gt; Point 7</td>\n",
       "      <td>51</td>\n",
       "      <td>28.51917</td>\n",
       "      <td>76.94864</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.2 km</td>\n",
       "      <td>9 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8851</th>\n",
       "      <td>Point 8 -&gt; Point 7</td>\n",
       "      <td>52</td>\n",
       "      <td>28.51917</td>\n",
       "      <td>76.94953</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.2 km</td>\n",
       "      <td>9 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8852</th>\n",
       "      <td>Point 8 -&gt; Point 7</td>\n",
       "      <td>53</td>\n",
       "      <td>28.51916</td>\n",
       "      <td>76.94997</td>\n",
       "      <td>1.11</td>\n",
       "      <td>3.2 km</td>\n",
       "      <td>9 mins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8853 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Path_ID  Point_Order  Latitude  Longitude  Congestion_Factor  \\\n",
       "0     Point 0 -> Point 1            1  28.48000   76.93017               1.00   \n",
       "1     Point 0 -> Point 1            2  28.47953   76.93015               1.00   \n",
       "2     Point 0 -> Point 1            3  28.47958   76.93033               1.00   \n",
       "3     Point 0 -> Point 1            4  28.47974   76.93075               1.00   \n",
       "4     Point 0 -> Point 1            5  28.47982   76.93090               1.00   \n",
       "...                  ...          ...       ...        ...                ...   \n",
       "8848  Point 8 -> Point 7           49  28.52003   76.94858               1.11   \n",
       "8849  Point 8 -> Point 7           50  28.51917   76.94813               1.11   \n",
       "8850  Point 8 -> Point 7           51  28.51917   76.94864               1.11   \n",
       "8851  Point 8 -> Point 7           52  28.51917   76.94953               1.11   \n",
       "8852  Point 8 -> Point 7           53  28.51916   76.94997               1.11   \n",
       "\n",
       "     Distance_Text Duration_in_Traffic_Text  \n",
       "0           3.0 km                   9 mins  \n",
       "1           3.0 km                   9 mins  \n",
       "2           3.0 km                   9 mins  \n",
       "3           3.0 km                   9 mins  \n",
       "4           3.0 km                   9 mins  \n",
       "...            ...                      ...  \n",
       "8848        3.2 km                   9 mins  \n",
       "8849        3.2 km                   9 mins  \n",
       "8850        3.2 km                   9 mins  \n",
       "8851        3.2 km                   9 mins  \n",
       "8852        3.2 km                   9 mins  \n",
       "\n",
       "[8853 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableau_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885141f1",
   "metadata": {},
   "source": [
    "# Data for Delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48223ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import random\n",
    "import math\n",
    "import requests        \n",
    "import urllib.parse    \n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "API_KEY = \"use you api\" # change it with your TomTom API key\n",
    "\n",
    "\n",
    "\n",
    "PLACE_LIST = [\n",
    "    \"Delhi, India\",\n",
    "    \"Gurugram, India\",\n",
    "    \"Noida, India\",\n",
    "    \"Ghaziabad, India\",\n",
    "    \"Faridabad, India\"\n",
    "]\n",
    "\n",
    "COMBINED_PLACE_LIST = \"Mumbai\"\n",
    "\n",
    "POINTS_PER_ROAD_TYPE = 20 # Sample size per Road Type\n",
    "\n",
    "RANDOM_STATE = 77\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"traffic_report_{COMBINED_PLACE_LIST}_{timestamp}.csv\"\n",
    "OUTPUT_FILENAME = filename\n",
    "\n",
    "# --- Define the road types to process individually ---\n",
    "ROAD_TYPES_TO_PROCESS = ['motorway', 'trunk', 'primary', 'secondary','tertiary']\n",
    "\n",
    "# --- Helper functions to format TomTom's output (meters/seconds) ---\n",
    "\n",
    "def format_duration(seconds):\n",
    "    \"\"\"Converts seconds into a human-readable 'X hours Y mins' or 'Y mins' string.\"\"\"\n",
    "    if seconds is None:\n",
    "        return \"N/A\"\n",
    "    minutes = math.ceil(seconds / 60)\n",
    "    if minutes < 60:\n",
    "        return f\"{minutes} mins\"\n",
    "    else:\n",
    "        hours = minutes // 60\n",
    "        rem_minutes = minutes % 60\n",
    "        return f\"{hours} hours {rem_minutes} mins\"\n",
    "\n",
    "def format_distance(meters):\n",
    "    \"\"\"Converts meters into a human-readable 'X.Y km' string.\"\"\"\n",
    "    if meters is None:\n",
    "        return \"N/A\"\n",
    "    km = round(meters / 1000, 1)\n",
    "    return f\"{km} km\"\n",
    "\n",
    "# --- No TomTom Client Initialization needed ---\n",
    "\n",
    "# This list will hold data from all road type loops\n",
    "all_path_points_data = []\n",
    "\n",
    "print(f\"Starting traffic analysis for {PLACE_LIST}...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Main loop to process each road type separately ---\n",
    "for road_type in ROAD_TYPES_TO_PROCESS:\n",
    "    print(f\"\\nProcessing road type: '{road_type.upper()}'\")\n",
    "\n",
    "    graphs_for_this_road_type = []\n",
    "    print(f\"  Downloading '{road_type}' network from OpenStreetMap for {len(PLACE_LIST)} places...\")\n",
    "    for place in PLACE_LIST:\n",
    "        try:\n",
    "            # Fetch network for ONLY the current road type\n",
    "            road_filter = f'[\"highway\"~\"{road_type}\"]'\n",
    "            G_place = ox.graph_from_place(place, network_type='drive', custom_filter=road_filter)\n",
    "            \n",
    "            if G_place.nodes:\n",
    "                graphs_for_this_road_type.append(G_place)\n",
    "                print(f\"    - Successfully fetched '{road_type}' for {place}\")\n",
    "            else:\n",
    "                print(f\"    - No '{road_type}' roads found in {place}.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    - Error fetching data for {place}: {e}\")\n",
    "    \n",
    "    if not graphs_for_this_road_type:\n",
    "        print(f\"  - No '{road_type}' roads found in any specified location. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"  Combining {len(graphs_for_this_road_type)} graphs for '{road_type}'...\")\n",
    "    G = nx.compose_all(graphs_for_this_road_type)\n",
    "\n",
    "    try:\n",
    "        if not G.nodes:\n",
    "            print(f\"  - Combined graph for '{road_type}' is empty. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Get all points for this specific network\n",
    "        nodes = list(G.nodes)\n",
    "        all_road_points = [(G.nodes[node]['y'], G.nodes[node]['x']) for node in nodes]\n",
    "        print(f\"  Found {len(all_road_points)} total points for this road type.\")\n",
    "\n",
    "        if len(all_road_points) < 2:\n",
    "            print(f\"  - Not enough points ({len(all_road_points)}) to create paths. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Take a random sample of these points\n",
    "        random.seed(RANDOM_STATE)\n",
    "        sample_size = min(POINTS_PER_ROAD_TYPE, len(all_road_points))\n",
    "        sampled_points = random.sample(all_road_points, sample_size)\n",
    "        print(f\"  Using a random sample of {len(sampled_points)} points.\")\n",
    "\n",
    "        # Generate paths and get traffic data for this sample\n",
    "        total_paths = len(sampled_points) * (len(sampled_points) - 1)\n",
    "        path_counter = 0\n",
    "\n",
    "        if total_paths == 0:\n",
    "            print(\"  - Only one point sampled, cannot create paths. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Starting TomTom API calls for {total_paths} paths...\")\n",
    "        for i, origin in enumerate(sampled_points):\n",
    "            for j, destination in enumerate(sampled_points):\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                path_counter += 1\n",
    "                \n",
    "                # --- TomTom API Call using 'requests' ---\n",
    "                try:\n",
    "                    origin_str = f\"{origin[0]},{origin[1]}\"\n",
    "                    dest_str = f\"{destination[0]},{destination[1]}\"\n",
    "                    \n",
    "                    locations = urllib.parse.quote(f\"{origin_str}:{dest_str}\")\n",
    "                    \n",
    "                    depart_at_iso = datetime.now().isoformat()\n",
    "\n",
    "                    base_url = f\"https://api.tomtom.com/routing/1/calculateRoute/{locations}/json\"\n",
    "                    \n",
    "                    params = {\n",
    "                        'key': API_KEY,\n",
    "                        'departAt': depart_at_iso,\n",
    "                        'traffic': 'true',\n",
    "                        'computeTravelTimeFor': 'all', # Request both traffic and no-traffic times\n",
    "                        'travelMode': 'car',\n",
    "                        'routeType': 'fastest'\n",
    "                    }\n",
    "\n",
    "                    # Make the GET request\n",
    "                    response = requests.get(base_url, params=params)\n",
    "                    response.raise_for_status() # Raise an exception for bad status codes (4xx, 5xx)\n",
    "                    \n",
    "                    directions_result = response.json()\n",
    "\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"      - TomTom API Error for path {i}-to-{j}: {e}\")\n",
    "                    continue \n",
    "\n",
    "                if not directions_result or 'routes' not in directions_result or not directions_result['routes']:\n",
    "                    print(f\"      - No route found by TomTom for path {i}-to-{j}.\")\n",
    "                    continue\n",
    "                # --- End TomTom API Call ---\n",
    "\n",
    "                # --- Extract TomTom Info ---\n",
    "                route = directions_result['routes'][0]\n",
    "                summary = route['summary']\n",
    "\n",
    "                duration_val = summary.get('noTrafficTravelTimeInSeconds')\n",
    "                duration_traffic_val = summary.get('travelTimeInSeconds')\n",
    "                distance_val_meters = summary.get('lengthInMeters')\n",
    "                \n",
    "                # Handle cases where one value might be missing\n",
    "                if duration_val is None:\n",
    "                    duration_val = duration_traffic_val\n",
    "                if duration_traffic_val is None:\n",
    "                    duration_traffic_val = duration_val\n",
    "                if duration_val is None or duration_traffic_val is None:\n",
    "                    print(f\"      - Missing duration data for path {i}-to-{j}. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Calculate congestion\n",
    "                congestion_factor = duration_traffic_val / duration_val if duration_val > 0 else 1\n",
    "\n",
    "                leg = route['legs'][0]\n",
    "                decoded_path = leg['points'] \n",
    "\n",
    "                # Get text representations using our helper functions\n",
    "                distance_text = format_distance(distance_val_meters)\n",
    "                duration_traffic_text = format_duration(duration_traffic_val)\n",
    "                \n",
    "                path_id = f\"{road_type.capitalize()}_{i}_to_{j}\"\n",
    "                # --- End TomTom Info Extraction ---\n",
    "\n",
    "                # Append data for each point in the path to the main list\n",
    "                for order, point in enumerate(decoded_path):\n",
    "                    all_path_points_data.append({\n",
    "                        'Path_ID': path_id,\n",
    "                        'Road_Type': road_type,\n",
    "                        'Point_Order': order + 1,\n",
    "                        # Note: TomTom uses 'latitude' and 'longitude'\n",
    "                        'Latitude': point['latitude'], \n",
    "                        'Longitude': point['longitude'],\n",
    "                        'Congestion_Factor': round(congestion_factor, 2),\n",
    "                        'Distance_Text': distance_text,\n",
    "                        'Duration_in_Traffic_Text': duration_traffic_text,\n",
    "                        'Duration_Value': duration_val # Base duration without traffic\n",
    "                    })\n",
    "        print(f\"  Finished processing '{road_type}' paths.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  An error occurred while processing '{road_type}': {e}\")\n",
    "        print(\"  This might happen if the road type doesn't exist in the specified area.\")\n",
    "\n",
    "# --- Save Combined Data to a Single CSV ---\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nCombining data from all road types and saving to CSV...\")\n",
    "final__df = pd.DataFrame(all_path_points_data)\n",
    "final__df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "print(f\"\\n Successfully generated combined traffic data!\")\n",
    "print(f\"'{OUTPUT_FILENAME}' is now ready for Tableau.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074004c9",
   "metadata": {},
   "source": [
    "# Data For Mumbai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f747a784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting traffic analysis for ['Mumbai, India', 'Navi Mumbai, India', 'Thane, India', 'Kalyan-Dombivli, India', 'Vasai-Virar, India', 'Mira-Bhayandar, India', 'Panvel, India', 'Ulhasnagar, India']...\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing road type: 'MOTORWAY'\n",
      "  Downloading 'motorway' network from OpenStreetMap for 8 places...\n",
      "    - Successfully fetched 'motorway' for Mumbai, India\n",
      "    - Successfully fetched 'motorway' for Navi Mumbai, India\n",
      "    - Successfully fetched 'motorway' for Thane, India\n",
      "    - Error fetching data for Kalyan-Dombivli, India: No data elements in server response. Check query location/filters and log.\n",
      "    - Error fetching data for Vasai-Virar, India: No data elements in server response. Check query location/filters and log.\n",
      "    - Error fetching data for Mira-Bhayandar, India: Nominatim did not geocode query 'Mira-Bhayandar, India' to a geometry of type (Multi)Polygon.\n",
      "    - Error fetching data for Panvel, India: No data elements in server response. Check query location/filters and log.\n",
      "    - Error fetching data for Ulhasnagar, India: No data elements in server response. Check query location/filters and log.\n",
      "  Combining 3 graphs for 'motorway'...\n",
      "  Found 108 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting TomTom API calls for 380 paths...\n",
      "  Finished processing 'motorway' paths.\n",
      "\n",
      "Processing road type: 'TRUNK'\n",
      "  Downloading 'trunk' network from OpenStreetMap for 8 places...\n",
      "    - Successfully fetched 'trunk' for Mumbai, India\n",
      "    - Successfully fetched 'trunk' for Navi Mumbai, India\n",
      "    - Successfully fetched 'trunk' for Thane, India\n",
      "    - Successfully fetched 'trunk' for Kalyan-Dombivli, India\n",
      "    - Successfully fetched 'trunk' for Vasai-Virar, India\n",
      "    - Error fetching data for Mira-Bhayandar, India: Nominatim did not geocode query 'Mira-Bhayandar, India' to a geometry of type (Multi)Polygon.\n",
      "    - Error fetching data for Panvel, India: Found no graph nodes within the requested polygon.\n",
      "    - Successfully fetched 'trunk' for Ulhasnagar, India\n",
      "  Combining 6 graphs for 'trunk'...\n",
      "  Found 498 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting TomTom API calls for 380 paths...\n",
      "      - TomTom API Error for path 17-to-5: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "  Finished processing 'trunk' paths.\n",
      "\n",
      "Processing road type: 'PRIMARY'\n",
      "  Downloading 'primary' network from OpenStreetMap for 8 places...\n",
      "    - Successfully fetched 'primary' for Mumbai, India\n",
      "    - Successfully fetched 'primary' for Navi Mumbai, India\n",
      "    - Successfully fetched 'primary' for Thane, India\n",
      "    - Successfully fetched 'primary' for Kalyan-Dombivli, India\n",
      "    - Successfully fetched 'primary' for Vasai-Virar, India\n",
      "    - Error fetching data for Mira-Bhayandar, India: Nominatim did not geocode query 'Mira-Bhayandar, India' to a geometry of type (Multi)Polygon.\n",
      "    - Error fetching data for Panvel, India: Found no graph nodes within the requested polygon.\n",
      "    - Successfully fetched 'primary' for Ulhasnagar, India\n",
      "  Combining 6 graphs for 'primary'...\n",
      "  Found 857 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting TomTom API calls for 380 paths...\n",
      "      - TomTom API Error for path 19-to-6: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "  Finished processing 'primary' paths.\n",
      "\n",
      "Processing road type: 'SECONDARY'\n",
      "  Downloading 'secondary' network from OpenStreetMap for 8 places...\n",
      "    - Successfully fetched 'secondary' for Mumbai, India\n",
      "    - Successfully fetched 'secondary' for Navi Mumbai, India\n",
      "    - Successfully fetched 'secondary' for Thane, India\n",
      "    - Successfully fetched 'secondary' for Kalyan-Dombivli, India\n",
      "    - Successfully fetched 'secondary' for Vasai-Virar, India\n",
      "    - Error fetching data for Mira-Bhayandar, India: Nominatim did not geocode query 'Mira-Bhayandar, India' to a geometry of type (Multi)Polygon.\n",
      "    - Error fetching data for Panvel, India: Found no graph nodes within the requested polygon.\n",
      "    - Successfully fetched 'secondary' for Ulhasnagar, India\n",
      "  Combining 6 graphs for 'secondary'...\n",
      "  Found 829 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting TomTom API calls for 380 paths...\n",
      "      - TomTom API Error for path 8-to-12: HTTPSConnectionPool(host='api.tomtom.com', port=443): Read timed out. (read timeout=None)\n",
      "  Finished processing 'secondary' paths.\n",
      "\n",
      "Processing road type: 'TERTIARY'\n",
      "  Downloading 'tertiary' network from OpenStreetMap for 8 places...\n",
      "    - Successfully fetched 'tertiary' for Mumbai, India\n",
      "    - Successfully fetched 'tertiary' for Navi Mumbai, India\n",
      "    - Successfully fetched 'tertiary' for Thane, India\n",
      "    - Successfully fetched 'tertiary' for Kalyan-Dombivli, India\n",
      "    - Successfully fetched 'tertiary' for Vasai-Virar, India\n",
      "    - Error fetching data for Mira-Bhayandar, India: Nominatim did not geocode query 'Mira-Bhayandar, India' to a geometry of type (Multi)Polygon.\n",
      "    - Error fetching data for Panvel, India: Found no graph nodes within the requested polygon.\n",
      "    - Successfully fetched 'tertiary' for Ulhasnagar, India\n",
      "  Combining 6 graphs for 'tertiary'...\n",
      "  Found 648 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting TomTom API calls for 380 paths...\n",
      "      - TomTom API Error for path 6-to-12: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "  Finished processing 'tertiary' paths.\n",
      "--------------------------------------------------\n",
      "\n",
      "Combining data from all road types and saving to CSV...\n",
      "\n",
      " Successfully generated combined traffic data!\n",
      "'traffic_report_Kolkata_2025-10-19_23-04-47.csv' is now ready for Tableau.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import random\n",
    "import math\n",
    "import requests        \n",
    "import urllib.parse    \n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "API_KEY = \"   \" # change it with your TomTom API key\n",
    "\n",
    "\n",
    "PLACE_LIST = [\n",
    "    \"Mumbai, India\",\n",
    "    \"Navi Mumbai, India\",\n",
    "    \"Thane, India\",\n",
    "    \"Kalyan-Dombivli, India\",\n",
    "    \"Vasai-Virar, India\",\n",
    "    \"Mira-Bhayandar, India\",\n",
    "    \"Panvel, India\",\n",
    "    \"Ulhasnagar, India\"\n",
    "]\n",
    "\n",
    "COMBINED_PLACE_LIST = \"Mumbai\"\n",
    "\n",
    "POINTS_PER_ROAD_TYPE = 20 # Sample size per Road Type\n",
    "\n",
    "RANDOM_STATE = 77\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"traffic_report_{COMBINED_PLACE_LIST}_{timestamp}.csv\"\n",
    "OUTPUT_FILENAME = filename\n",
    "\n",
    "# --- Define the road types to process individually ---\n",
    "ROAD_TYPES_TO_PROCESS = ['motorway', 'trunk', 'primary', 'secondary','tertiary']\n",
    "\n",
    "# --- Helper functions to format TomTom's output (meters/seconds) ---\n",
    "\n",
    "def format_duration(seconds):\n",
    "    \"\"\"Converts seconds into a human-readable 'X hours Y mins' or 'Y mins' string.\"\"\"\n",
    "    if seconds is None:\n",
    "        return \"N/A\"\n",
    "    minutes = math.ceil(seconds / 60)\n",
    "    if minutes < 60:\n",
    "        return f\"{minutes} mins\"\n",
    "    else:\n",
    "        hours = minutes // 60\n",
    "        rem_minutes = minutes % 60\n",
    "        return f\"{hours} hours {rem_minutes} mins\"\n",
    "\n",
    "def format_distance(meters):\n",
    "    \"\"\"Converts meters into a human-readable 'X.Y km' string.\"\"\"\n",
    "    if meters is None:\n",
    "        return \"N/A\"\n",
    "    km = round(meters / 1000, 1)\n",
    "    return f\"{km} km\"\n",
    "\n",
    "# --- No TomTom Client Initialization needed ---\n",
    "\n",
    "# This list will hold data from all road type loops\n",
    "all_path_points_data = []\n",
    "\n",
    "print(f\"Starting traffic analysis for {PLACE_LIST}...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Main loop to process each road type separately ---\n",
    "for road_type in ROAD_TYPES_TO_PROCESS:\n",
    "    print(f\"\\nProcessing road type: '{road_type.upper()}'\")\n",
    "\n",
    "    graphs_for_this_road_type = []\n",
    "    print(f\"  Downloading '{road_type}' network from OpenStreetMap for {len(PLACE_LIST)} places...\")\n",
    "    for place in PLACE_LIST:\n",
    "        try:\n",
    "            # Fetch network for ONLY the current road type\n",
    "            road_filter = f'[\"highway\"~\"{road_type}\"]'\n",
    "            G_place = ox.graph_from_place(place, network_type='drive', custom_filter=road_filter)\n",
    "            \n",
    "            if G_place.nodes:\n",
    "                graphs_for_this_road_type.append(G_place)\n",
    "                print(f\"    - Successfully fetched '{road_type}' for {place}\")\n",
    "            else:\n",
    "                print(f\"    - No '{road_type}' roads found in {place}.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    - Error fetching data for {place}: {e}\")\n",
    "    \n",
    "    if not graphs_for_this_road_type:\n",
    "        print(f\"  - No '{road_type}' roads found in any specified location. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"  Combining {len(graphs_for_this_road_type)} graphs for '{road_type}'...\")\n",
    "    G = nx.compose_all(graphs_for_this_road_type)\n",
    "\n",
    "    try:\n",
    "        if not G.nodes:\n",
    "            print(f\"  - Combined graph for '{road_type}' is empty. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Get all points for this specific network\n",
    "        nodes = list(G.nodes)\n",
    "        all_road_points = [(G.nodes[node]['y'], G.nodes[node]['x']) for node in nodes]\n",
    "        print(f\"  Found {len(all_road_points)} total points for this road type.\")\n",
    "\n",
    "        if len(all_road_points) < 2:\n",
    "            print(f\"  - Not enough points ({len(all_road_points)}) to create paths. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Take a random sample of these points\n",
    "        random.seed(RANDOM_STATE)\n",
    "        sample_size = min(POINTS_PER_ROAD_TYPE, len(all_road_points))\n",
    "        sampled_points = random.sample(all_road_points, sample_size)\n",
    "        print(f\"  Using a random sample of {len(sampled_points)} points.\")\n",
    "\n",
    "        # Generate paths and get traffic data for this sample\n",
    "        total_paths = len(sampled_points) * (len(sampled_points) - 1)\n",
    "        path_counter = 0\n",
    "\n",
    "        if total_paths == 0:\n",
    "            print(\"  - Only one point sampled, cannot create paths. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Starting TomTom API calls for {total_paths} paths...\")\n",
    "        for i, origin in enumerate(sampled_points):\n",
    "            for j, destination in enumerate(sampled_points):\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                path_counter += 1\n",
    "                \n",
    "                # --- TomTom API Call using 'requests' ---\n",
    "                try:\n",
    "                    origin_str = f\"{origin[0]},{origin[1]}\"\n",
    "                    dest_str = f\"{destination[0]},{destination[1]}\"\n",
    "                    \n",
    "                    locations = urllib.parse.quote(f\"{origin_str}:{dest_str}\")\n",
    "                    \n",
    "                    depart_at_iso = datetime.now().isoformat()\n",
    "\n",
    "                    base_url = f\"https://api.tomtom.com/routing/1/calculateRoute/{locations}/json\"\n",
    "                    \n",
    "                    params = {\n",
    "                        'key': API_KEY,\n",
    "                        'departAt': depart_at_iso,\n",
    "                        'traffic': 'true',\n",
    "                        'computeTravelTimeFor': 'all', # Request both traffic and no-traffic times\n",
    "                        'travelMode': 'car',\n",
    "                        'routeType': 'fastest'\n",
    "                    }\n",
    "\n",
    "                    # Make the GET request\n",
    "                    response = requests.get(base_url, params=params)\n",
    "                    response.raise_for_status() # Raise an exception for bad status codes (4xx, 5xx)\n",
    "                    \n",
    "                    directions_result = response.json()\n",
    "\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"      - TomTom API Error for path {i}-to-{j}: {e}\")\n",
    "                    continue \n",
    "\n",
    "                if not directions_result or 'routes' not in directions_result or not directions_result['routes']:\n",
    "                    print(f\"      - No route found by TomTom for path {i}-to-{j}.\")\n",
    "                    continue\n",
    "                # --- End TomTom API Call ---\n",
    "\n",
    "                # --- Extract TomTom Info ---\n",
    "                route = directions_result['routes'][0]\n",
    "                summary = route['summary']\n",
    "\n",
    "                duration_val = summary.get('noTrafficTravelTimeInSeconds')\n",
    "                duration_traffic_val = summary.get('travelTimeInSeconds')\n",
    "                distance_val_meters = summary.get('lengthInMeters')\n",
    "                \n",
    "                # Handle cases where one value might be missing\n",
    "                if duration_val is None:\n",
    "                    duration_val = duration_traffic_val\n",
    "                if duration_traffic_val is None:\n",
    "                    duration_traffic_val = duration_val\n",
    "                if duration_val is None or duration_traffic_val is None:\n",
    "                    print(f\"      - Missing duration data for path {i}-to-{j}. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Calculate congestion\n",
    "                congestion_factor = duration_traffic_val / duration_val if duration_val > 0 else 1\n",
    "\n",
    "                leg = route['legs'][0]\n",
    "                decoded_path = leg['points'] \n",
    "\n",
    "                # Get text representations using our helper functions\n",
    "                distance_text = format_distance(distance_val_meters)\n",
    "                duration_traffic_text = format_duration(duration_traffic_val)\n",
    "                \n",
    "                path_id = f\"{road_type.capitalize()}_{i}_to_{j}\"\n",
    "                # --- End TomTom Info Extraction ---\n",
    "\n",
    "                # Append data for each point in the path to the main list\n",
    "                for order, point in enumerate(decoded_path):\n",
    "                    all_path_points_data.append({\n",
    "                        'Path_ID': path_id,\n",
    "                        'Road_Type': road_type,\n",
    "                        'Point_Order': order + 1,\n",
    "                        # Note: TomTom uses 'latitude' and 'longitude'\n",
    "                        'Latitude': point['latitude'], \n",
    "                        'Longitude': point['longitude'],\n",
    "                        'Congestion_Factor': round(congestion_factor, 2),\n",
    "                        'Distance_Text': distance_text,\n",
    "                        'Duration_in_Traffic_Text': duration_traffic_text,\n",
    "                        'Duration_Value': duration_val # Base duration without traffic\n",
    "                    })\n",
    "        print(f\"  Finished processing '{road_type}' paths.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  An error occurred while processing '{road_type}': {e}\")\n",
    "        print(\"  This might happen if the road type doesn't exist in the specified area.\")\n",
    "\n",
    "# --- Save Combined Data to a Single CSV ---\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nCombining data from all road types and saving to CSV...\")\n",
    "final__df = pd.DataFrame(all_path_points_data)\n",
    "final__df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "print(f\"\\n Successfully generated combined traffic data!\")\n",
    "print(f\"'{OUTPUT_FILENAME}' is now ready for Tableau.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be361bf7",
   "metadata": {},
   "source": [
    "# Data for Banglore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97591d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import random\n",
    "import math\n",
    "import requests        \n",
    "import urllib.parse    \n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "API_KEY = \"   \" # change it with your TomTom API key\n",
    "\n",
    "PLACE_LIST = [\n",
    "    \"Bengaluru, India\",\n",
    "    \"Hoskote, India\",\n",
    "    \"Devanahalli, India\",\n",
    "    \"Doddaballapura, India\",\n",
    "    \"Nelamangala, India\",\n",
    "    \"Magadi, India\",\n",
    "    \"Ramanagara, India\",\n",
    "    \"Kanakapura, India\",\n",
    "    \"Anekal, India\",\n",
    "    \"Sarjapur, India\",\n",
    "    \"Bidadi, India\"\n",
    "]\n",
    "\n",
    "\n",
    "COMBINED_PLACE_LIST = \"Mumbai\"\n",
    "\n",
    "POINTS_PER_ROAD_TYPE = 20 # Sample size per Road Type\n",
    "\n",
    "RANDOM_STATE = 77\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"traffic_report_{COMBINED_PLACE_LIST}_{timestamp}.csv\"\n",
    "OUTPUT_FILENAME = filename\n",
    "\n",
    "# --- Define the road types to process individually ---\n",
    "ROAD_TYPES_TO_PROCESS = ['motorway', 'trunk', 'primary', 'secondary','tertiary']\n",
    "\n",
    "# --- Helper functions to format TomTom's output (meters/seconds) ---\n",
    "\n",
    "def format_duration(seconds):\n",
    "    \"\"\"Converts seconds into a human-readable 'X hours Y mins' or 'Y mins' string.\"\"\"\n",
    "    if seconds is None:\n",
    "        return \"N/A\"\n",
    "    minutes = math.ceil(seconds / 60)\n",
    "    if minutes < 60:\n",
    "        return f\"{minutes} mins\"\n",
    "    else:\n",
    "        hours = minutes // 60\n",
    "        rem_minutes = minutes % 60\n",
    "        return f\"{hours} hours {rem_minutes} mins\"\n",
    "\n",
    "def format_distance(meters):\n",
    "    \"\"\"Converts meters into a human-readable 'X.Y km' string.\"\"\"\n",
    "    if meters is None:\n",
    "        return \"N/A\"\n",
    "    km = round(meters / 1000, 1)\n",
    "    return f\"{km} km\"\n",
    "\n",
    "# --- No TomTom Client Initialization needed ---\n",
    "\n",
    "# This list will hold data from all road type loops\n",
    "all_path_points_data = []\n",
    "\n",
    "print(f\"Starting traffic analysis for {PLACE_LIST}...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Main loop to process each road type separately ---\n",
    "for road_type in ROAD_TYPES_TO_PROCESS:\n",
    "    print(f\"\\nProcessing road type: '{road_type.upper()}'\")\n",
    "\n",
    "    graphs_for_this_road_type = []\n",
    "    print(f\"  Downloading '{road_type}' network from OpenStreetMap for {len(PLACE_LIST)} places...\")\n",
    "    for place in PLACE_LIST:\n",
    "        try:\n",
    "            # Fetch network for ONLY the current road type\n",
    "            road_filter = f'[\"highway\"~\"{road_type}\"]'\n",
    "            G_place = ox.graph_from_place(place, network_type='drive', custom_filter=road_filter)\n",
    "            \n",
    "            if G_place.nodes:\n",
    "                graphs_for_this_road_type.append(G_place)\n",
    "                print(f\"    - Successfully fetched '{road_type}' for {place}\")\n",
    "            else:\n",
    "                print(f\"    - No '{road_type}' roads found in {place}.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    - Error fetching data for {place}: {e}\")\n",
    "    \n",
    "    if not graphs_for_this_road_type:\n",
    "        print(f\"  - No '{road_type}' roads found in any specified location. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"  Combining {len(graphs_for_this_road_type)} graphs for '{road_type}'...\")\n",
    "    G = nx.compose_all(graphs_for_this_road_type)\n",
    "\n",
    "    try:\n",
    "        if not G.nodes:\n",
    "            print(f\"  - Combined graph for '{road_type}' is empty. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Get all points for this specific network\n",
    "        nodes = list(G.nodes)\n",
    "        all_road_points = [(G.nodes[node]['y'], G.nodes[node]['x']) for node in nodes]\n",
    "        print(f\"  Found {len(all_road_points)} total points for this road type.\")\n",
    "\n",
    "        if len(all_road_points) < 2:\n",
    "            print(f\"  - Not enough points ({len(all_road_points)}) to create paths. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Take a random sample of these points\n",
    "        random.seed(RANDOM_STATE)\n",
    "        sample_size = min(POINTS_PER_ROAD_TYPE, len(all_road_points))\n",
    "        sampled_points = random.sample(all_road_points, sample_size)\n",
    "        print(f\"  Using a random sample of {len(sampled_points)} points.\")\n",
    "\n",
    "        # Generate paths and get traffic data for this sample\n",
    "        total_paths = len(sampled_points) * (len(sampled_points) - 1)\n",
    "        path_counter = 0\n",
    "\n",
    "        if total_paths == 0:\n",
    "            print(\"  - Only one point sampled, cannot create paths. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Starting TomTom API calls for {total_paths} paths...\")\n",
    "        for i, origin in enumerate(sampled_points):\n",
    "            for j, destination in enumerate(sampled_points):\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                path_counter += 1\n",
    "                \n",
    "                # --- TomTom API Call using 'requests' ---\n",
    "                try:\n",
    "                    origin_str = f\"{origin[0]},{origin[1]}\"\n",
    "                    dest_str = f\"{destination[0]},{destination[1]}\"\n",
    "                    \n",
    "                    locations = urllib.parse.quote(f\"{origin_str}:{dest_str}\")\n",
    "                    \n",
    "                    depart_at_iso = datetime.now().isoformat()\n",
    "\n",
    "                    base_url = f\"https://api.tomtom.com/routing/1/calculateRoute/{locations}/json\"\n",
    "                    \n",
    "                    params = {\n",
    "                        'key': API_KEY,\n",
    "                        'departAt': depart_at_iso,\n",
    "                        'traffic': 'true',\n",
    "                        'computeTravelTimeFor': 'all', # Request both traffic and no-traffic times\n",
    "                        'travelMode': 'car',\n",
    "                        'routeType': 'fastest'\n",
    "                    }\n",
    "\n",
    "                    # Make the GET request\n",
    "                    response = requests.get(base_url, params=params)\n",
    "                    response.raise_for_status() # Raise an exception for bad status codes (4xx, 5xx)\n",
    "                    \n",
    "                    directions_result = response.json()\n",
    "\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"      - TomTom API Error for path {i}-to-{j}: {e}\")\n",
    "                    continue \n",
    "\n",
    "                if not directions_result or 'routes' not in directions_result or not directions_result['routes']:\n",
    "                    print(f\"      - No route found by TomTom for path {i}-to-{j}.\")\n",
    "                    continue\n",
    "                # --- End TomTom API Call ---\n",
    "\n",
    "                # --- Extract TomTom Info ---\n",
    "                route = directions_result['routes'][0]\n",
    "                summary = route['summary']\n",
    "\n",
    "                duration_val = summary.get('noTrafficTravelTimeInSeconds')\n",
    "                duration_traffic_val = summary.get('travelTimeInSeconds')\n",
    "                distance_val_meters = summary.get('lengthInMeters')\n",
    "                \n",
    "                # Handle cases where one value might be missing\n",
    "                if duration_val is None:\n",
    "                    duration_val = duration_traffic_val\n",
    "                if duration_traffic_val is None:\n",
    "                    duration_traffic_val = duration_val\n",
    "                if duration_val is None or duration_traffic_val is None:\n",
    "                    print(f\"      - Missing duration data for path {i}-to-{j}. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Calculate congestion\n",
    "                congestion_factor = duration_traffic_val / duration_val if duration_val > 0 else 1\n",
    "\n",
    "                leg = route['legs'][0]\n",
    "                decoded_path = leg['points'] \n",
    "\n",
    "                # Get text representations using our helper functions\n",
    "                distance_text = format_distance(distance_val_meters)\n",
    "                duration_traffic_text = format_duration(duration_traffic_val)\n",
    "                \n",
    "                path_id = f\"{road_type.capitalize()}_{i}_to_{j}\"\n",
    "                # --- End TomTom Info Extraction ---\n",
    "\n",
    "                # Append data for each point in the path to the main list\n",
    "                for order, point in enumerate(decoded_path):\n",
    "                    all_path_points_data.append({\n",
    "                        'Path_ID': path_id,\n",
    "                        'Road_Type': road_type,\n",
    "                        'Point_Order': order + 1,\n",
    "                        # Note: TomTom uses 'latitude' and 'longitude'\n",
    "                        'Latitude': point['latitude'], \n",
    "                        'Longitude': point['longitude'],\n",
    "                        'Congestion_Factor': round(congestion_factor, 2),\n",
    "                        'Distance_Text': distance_text,\n",
    "                        'Duration_in_Traffic_Text': duration_traffic_text,\n",
    "                        'Duration_Value': duration_val # Base duration without traffic\n",
    "                    })\n",
    "        print(f\"  Finished processing '{road_type}' paths.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  An error occurred while processing '{road_type}': {e}\")\n",
    "        print(\"  This might happen if the road type doesn't exist in the specified area.\")\n",
    "\n",
    "# --- Save Combined Data to a Single CSV ---\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nCombining data from all road types and saving to CSV...\")\n",
    "final__df = pd.DataFrame(all_path_points_data)\n",
    "final__df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "print(f\"\\n Successfully generated combined traffic data!\")\n",
    "print(f\"'{OUTPUT_FILENAME}' is now ready for Tableau.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b7a04f",
   "metadata": {},
   "source": [
    "# Kolkata data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa6ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\pyenv\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting traffic analysis for ['Kolkata, India', 'Howrah, India', 'Bidhannagar, India', 'New Town, Kolkata, India', 'Rajpur Sonarpur, India', 'Maheshtala, India', 'Baranagar, India', 'Dum Dum, India', 'Serampore, India']...\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing road type: 'MOTORWAY'\n",
      "  Downloading 'motorway' network from OpenStreetMap for 9 places...\n",
      "  Downloading 'motorway' network from OpenStreetMap...\n",
      "    - Successfully fetched 'motorway' for Kolkata, India\n",
      "  Combining 1 graphs for 'motorway'...\n",
      "  Found 8 total points for this road type.\n",
      "  Using a random sample of 8 points.\n",
      "  Starting Google Maps API calls for 56 paths...\n",
      "  Finished processing 'motorway' paths.\n",
      "  Downloading 'motorway' network from OpenStreetMap...\n",
      "    - Successfully fetched 'motorway' for Howrah, India\n",
      "  Combining 2 graphs for 'motorway'...\n",
      "  Found 14 total points for this road type.\n",
      "  Using a random sample of 14 points.\n",
      "  Starting Google Maps API calls for 182 paths...\n",
      "  Finished processing 'motorway' paths.\n",
      "  Downloading 'motorway' network from OpenStreetMap...\n",
      "    - Error fetching data for Bidhannagar, India: No data elements in server response. Check query location/filters and log.\n",
      "  Combining 2 graphs for 'motorway'...\n",
      "  Found 14 total points for this road type.\n",
      "  Using a random sample of 14 points.\n",
      "  Starting Google Maps API calls for 182 paths...\n",
      "  Finished processing 'motorway' paths.\n",
      "  Downloading 'motorway' network from OpenStreetMap...\n",
      "    - Error fetching data for New Town, Kolkata, India: Nominatim did not geocode query 'New Town, Kolkata, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 2 graphs for 'motorway'...\n",
      "  Found 14 total points for this road type.\n",
      "  Using a random sample of 14 points.\n",
      "  Starting Google Maps API calls for 182 paths...\n",
      "  Finished processing 'motorway' paths.\n",
      "  Downloading 'motorway' network from OpenStreetMap...\n",
      "    - Error fetching data for Rajpur Sonarpur, India: No data elements in server response. Check query location/filters and log.\n",
      "  Combining 2 graphs for 'motorway'...\n",
      "  Found 14 total points for this road type.\n",
      "  Using a random sample of 14 points.\n",
      "  Starting Google Maps API calls for 182 paths...\n",
      "  Finished processing 'motorway' paths.\n",
      "  Downloading 'motorway' network from OpenStreetMap...\n",
      "    - Error fetching data for Maheshtala, India: No data elements in server response. Check query location/filters and log.\n",
      "  Combining 2 graphs for 'motorway'...\n",
      "  Found 14 total points for this road type.\n",
      "  Using a random sample of 14 points.\n",
      "  Starting Google Maps API calls for 182 paths...\n",
      "  Finished processing 'motorway' paths.\n",
      "  Downloading 'motorway' network from OpenStreetMap...\n",
      "    - Error fetching data for Baranagar, India: Nominatim did not geocode query 'Baranagar, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 2 graphs for 'motorway'...\n",
      "  Found 14 total points for this road type.\n",
      "  Using a random sample of 14 points.\n",
      "  Starting Google Maps API calls for 182 paths...\n",
      "  Finished processing 'motorway' paths.\n",
      "  Downloading 'motorway' network from OpenStreetMap...\n",
      "    - Error fetching data for Dum Dum, India: Nominatim did not geocode query 'Dum Dum, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 2 graphs for 'motorway'...\n",
      "  Found 14 total points for this road type.\n",
      "  Using a random sample of 14 points.\n",
      "  Starting Google Maps API calls for 182 paths...\n",
      "  Finished processing 'motorway' paths.\n",
      "  Downloading 'motorway' network from OpenStreetMap...\n",
      "    - Error fetching data for Serampore, India: Nominatim did not geocode query 'Serampore, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 2 graphs for 'motorway'...\n",
      "  Found 14 total points for this road type.\n",
      "  Using a random sample of 14 points.\n",
      "  Starting Google Maps API calls for 182 paths...\n",
      "  Finished processing 'motorway' paths.\n",
      "\n",
      "Processing road type: 'TRUNK'\n",
      "  Downloading 'trunk' network from OpenStreetMap for 9 places...\n",
      "  Downloading 'trunk' network from OpenStreetMap...\n",
      "    - Successfully fetched 'trunk' for Kolkata, India\n",
      "  Combining 1 graphs for 'trunk'...\n",
      "  Found 31 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  Finished processing 'trunk' paths.\n",
      "  Downloading 'trunk' network from OpenStreetMap...\n",
      "    - Successfully fetched 'trunk' for Howrah, India\n",
      "  Combining 2 graphs for 'trunk'...\n",
      "  Found 39 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  Finished processing 'trunk' paths.\n",
      "  Downloading 'trunk' network from OpenStreetMap...\n",
      "    - Error fetching data for Bidhannagar, India: No data elements in server response. Check query location/filters and log.\n",
      "  Combining 2 graphs for 'trunk'...\n",
      "  Found 39 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  Finished processing 'trunk' paths.\n",
      "  Downloading 'trunk' network from OpenStreetMap...\n",
      "    - Error fetching data for New Town, Kolkata, India: Nominatim did not geocode query 'New Town, Kolkata, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 2 graphs for 'trunk'...\n",
      "  Found 39 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  Finished processing 'trunk' paths.\n",
      "  Downloading 'trunk' network from OpenStreetMap...\n",
      "    - Error fetching data for Rajpur Sonarpur, India: No data elements in server response. Check query location/filters and log.\n",
      "  Combining 2 graphs for 'trunk'...\n",
      "  Found 39 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'trunk': ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'trunk' network from OpenStreetMap...\n",
      "    - Error fetching data for Maheshtala, India: No data elements in server response. Check query location/filters and log.\n",
      "  Combining 2 graphs for 'trunk'...\n",
      "  Found 39 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'trunk': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760881278&destination=22.5219608%2C88.3245221&mode=driving&origin=22.4746536%2C88.3098718&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3742E1A30>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'trunk' network from OpenStreetMap...\n",
      "    - Error fetching data for Baranagar, India: Nominatim did not geocode query 'Baranagar, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 2 graphs for 'trunk'...\n",
      "  Found 39 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'trunk': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760881278&destination=22.5219608%2C88.3245221&mode=driving&origin=22.4746536%2C88.3098718&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3742E1D60>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'trunk' network from OpenStreetMap...\n",
      "    - Error fetching data for Dum Dum, India: Nominatim did not geocode query 'Dum Dum, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 2 graphs for 'trunk'...\n",
      "  Found 39 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'trunk': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760881278&destination=22.5219608%2C88.3245221&mode=driving&origin=22.4746536%2C88.3098718&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3742E2060>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'trunk' network from OpenStreetMap...\n",
      "    - Error fetching data for Serampore, India: Nominatim did not geocode query 'Serampore, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 2 graphs for 'trunk'...\n",
      "  Found 39 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'trunk': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760881278&destination=22.5219608%2C88.3245221&mode=driving&origin=22.4746536%2C88.3098718&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3742E25A0>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "\n",
      "Processing road type: 'PRIMARY'\n",
      "  Downloading 'primary' network from OpenStreetMap for 9 places...\n",
      "  Downloading 'primary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'primary' for Kolkata, India\n",
      "  Combining 1 graphs for 'primary'...\n",
      "  Found 175 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'primary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760881279&destination=22.4794465%2C88.3760817&mode=driving&origin=22.4657012%2C88.3772284&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3742E2ED0>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'primary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'primary' for Howrah, India\n",
      "  Combining 2 graphs for 'primary'...\n",
      "  Found 222 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'primary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887584&destination=22.4657012%2C88.3772284&mode=driving&origin=22.5637212%2C88.3121125&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B374810080>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'primary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'primary' for Bidhannagar, India\n",
      "  Combining 3 graphs for 'primary'...\n",
      "  Found 301 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'primary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887584&destination=22.5416813%2C88.3628684&mode=driving&origin=22.5942839%2C88.375396&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B37498F680>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'primary' network from OpenStreetMap...\n",
      "    - Error fetching data for New Town, Kolkata, India: Nominatim did not geocode query 'New Town, Kolkata, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 3 graphs for 'primary'...\n",
      "  Found 301 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'primary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887584&destination=22.5416813%2C88.3628684&mode=driving&origin=22.5942839%2C88.375396&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B37498FF80>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'primary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'primary' for Rajpur Sonarpur, India\n",
      "  Combining 4 graphs for 'primary'...\n",
      "  Found 321 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'primary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887584&destination=22.5416813%2C88.3628684&mode=driving&origin=22.5942839%2C88.375396&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3749ADE80>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'primary' network from OpenStreetMap...\n",
      "    - Error fetching data for Maheshtala, India: No data elements in server response. Check query location/filters and log.\n",
      "  Combining 4 graphs for 'primary'...\n",
      "  Found 321 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'primary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887585&destination=22.5416813%2C88.3628684&mode=driving&origin=22.5942839%2C88.375396&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3749AC800>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'primary' network from OpenStreetMap...\n",
      "    - Error fetching data for Baranagar, India: Nominatim did not geocode query 'Baranagar, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 4 graphs for 'primary'...\n",
      "  Found 321 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'primary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887585&destination=22.5416813%2C88.3628684&mode=driving&origin=22.5942839%2C88.375396&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3749ACF80>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'primary' network from OpenStreetMap...\n",
      "    - Error fetching data for Dum Dum, India: Nominatim did not geocode query 'Dum Dum, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 4 graphs for 'primary'...\n",
      "  Found 321 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'primary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887585&destination=22.5416813%2C88.3628684&mode=driving&origin=22.5942839%2C88.375396&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3749AC800>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'primary' network from OpenStreetMap...\n",
      "    - Error fetching data for Serampore, India: Nominatim did not geocode query 'Serampore, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 4 graphs for 'primary'...\n",
      "  Found 321 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'primary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887585&destination=22.5416813%2C88.3628684&mode=driving&origin=22.5942839%2C88.375396&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3749AFEF0>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "\n",
      "Processing road type: 'SECONDARY'\n",
      "  Downloading 'secondary' network from OpenStreetMap for 9 places...\n",
      "  Downloading 'secondary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'secondary' for Kolkata, India\n",
      "  Combining 1 graphs for 'secondary'...\n",
      "  Found 362 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'secondary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887586&destination=22.5407978%2C88.3406801&mode=driving&origin=22.5436396%2C88.3656542&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3749C21E0>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'secondary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'secondary' for Howrah, India\n",
      "  Combining 2 graphs for 'secondary'...\n",
      "  Found 372 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'secondary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887586&destination=22.5407978%2C88.3406801&mode=driving&origin=22.5436396%2C88.3656542&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3749D4500>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'secondary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'secondary' for Bidhannagar, India\n",
      "  Combining 3 graphs for 'secondary'...\n",
      "  Found 429 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'secondary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887587&destination=22.5436396%2C88.3656542&mode=driving&origin=22.5838761%2C88.4154994&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3710BA510>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'secondary' network from OpenStreetMap...\n",
      "    - Error fetching data for New Town, Kolkata, India: Nominatim did not geocode query 'New Town, Kolkata, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 3 graphs for 'secondary'...\n",
      "  Found 429 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'secondary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887587&destination=22.5436396%2C88.3656542&mode=driving&origin=22.5838761%2C88.4154994&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3710BB890>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'secondary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'secondary' for Rajpur Sonarpur, India\n",
      "  Combining 4 graphs for 'secondary'...\n",
      "  Found 433 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'secondary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887587&destination=22.5436396%2C88.3656542&mode=driving&origin=22.5838761%2C88.4154994&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3705326F0>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'secondary' network from OpenStreetMap...\n",
      "    - Error fetching data for Maheshtala, India: Found no graph nodes within the requested polygon.\n",
      "  Combining 4 graphs for 'secondary'...\n",
      "  Found 433 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'secondary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887587&destination=22.5436396%2C88.3656542&mode=driving&origin=22.5838761%2C88.4154994&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B370543C50>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'secondary' network from OpenStreetMap...\n",
      "    - Error fetching data for Baranagar, India: Nominatim did not geocode query 'Baranagar, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 4 graphs for 'secondary'...\n",
      "  Found 433 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'secondary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887587&destination=22.5436396%2C88.3656542&mode=driving&origin=22.5838761%2C88.4154994&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3705404D0>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'secondary' network from OpenStreetMap...\n",
      "    - Error fetching data for Dum Dum, India: Nominatim did not geocode query 'Dum Dum, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 4 graphs for 'secondary'...\n",
      "  Found 433 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'secondary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887587&destination=22.5436396%2C88.3656542&mode=driving&origin=22.5838761%2C88.4154994&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3705409E0>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'secondary' network from OpenStreetMap...\n",
      "    - Error fetching data for Serampore, India: Nominatim did not geocode query 'Serampore, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 4 graphs for 'secondary'...\n",
      "  Found 433 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'secondary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887587&destination=22.5436396%2C88.3656542&mode=driving&origin=22.5838761%2C88.4154994&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B370542E40>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "\n",
      "Processing road type: 'TERTIARY'\n",
      "  Downloading 'tertiary' network from OpenStreetMap for 9 places...\n",
      "  Downloading 'tertiary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'tertiary' for Kolkata, India\n",
      "  Combining 1 graphs for 'tertiary'...\n",
      "  Found 125 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'tertiary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887588&destination=22.5579025%2C88.4115602&mode=driving&origin=22.5562461%2C88.3723671&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B370552810>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'tertiary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'tertiary' for Howrah, India\n",
      "  Combining 2 graphs for 'tertiary'...\n",
      "  Found 144 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'tertiary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887589&destination=22.5553818%2C88.3763783&mode=driving&origin=22.5384172%2C88.3863451&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B36B9F11C0>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'tertiary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'tertiary' for Bidhannagar, India\n",
      "  Combining 3 graphs for 'tertiary'...\n",
      "  Found 204 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'tertiary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887589&destination=22.5553818%2C88.3763783&mode=driving&origin=22.5384172%2C88.3863451&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B36B9D5DF0>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'tertiary' network from OpenStreetMap...\n",
      "    - Error fetching data for New Town, Kolkata, India: Nominatim did not geocode query 'New Town, Kolkata, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 3 graphs for 'tertiary'...\n",
      "  Found 204 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'tertiary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887589&destination=22.5553818%2C88.3763783&mode=driving&origin=22.5384172%2C88.3863451&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B36B9D7320>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'tertiary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'tertiary' for Rajpur Sonarpur, India\n",
      "  Combining 4 graphs for 'tertiary'...\n",
      "  Found 208 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'tertiary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887590&destination=22.5384172%2C88.3863451&mode=driving&origin=22.4437502%2C88.418075&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B374811FD0>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'tertiary' network from OpenStreetMap...\n",
      "    - Successfully fetched 'tertiary' for Maheshtala, India\n",
      "  Combining 5 graphs for 'tertiary'...\n",
      "  Found 241 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'tertiary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887590&destination=22.5384172%2C88.3863451&mode=driving&origin=22.4437502%2C88.418075&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3742E3140>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'tertiary' network from OpenStreetMap...\n",
      "    - Error fetching data for Baranagar, India: Nominatim did not geocode query 'Baranagar, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 5 graphs for 'tertiary'...\n",
      "  Found 241 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'tertiary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887590&destination=22.5384172%2C88.3863451&mode=driving&origin=22.4437502%2C88.418075&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3742E3350>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'tertiary' network from OpenStreetMap...\n",
      "    - Error fetching data for Dum Dum, India: Nominatim did not geocode query 'Dum Dum, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 5 graphs for 'tertiary'...\n",
      "  Found 241 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'tertiary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887590&destination=22.5384172%2C88.3863451&mode=driving&origin=22.4437502%2C88.418075&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3742E2270>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "  Downloading 'tertiary' network from OpenStreetMap...\n",
      "    - Error fetching data for Serampore, India: Nominatim did not geocode query 'Serampore, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 5 graphs for 'tertiary'...\n",
      "  Found 241 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting Google Maps API calls for 380 paths...\n",
      "  An error occurred while processing 'tertiary': HTTPSConnectionPool(host='maps.googleapis.com', port=443): Max retries exceeded with url: /maps/api/directions/json?departure_time=1760887590&destination=22.5384172%2C88.3863451&mode=driving&origin=22.4437502%2C88.418075&key=AIzaSyBURbksQ9YYXjriLHFZIh93ilXGkZJY4pE (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001B3742E1EB0>: Failed to resolve 'maps.googleapis.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  This might happen if the road type doesn't exist in the specified area.\n",
      "--------------------------------------------------\n",
      "\n",
      "Combining data from all road types and saving to CSV...\n",
      "\n",
      " Successfully generated combined traffic data!\n",
      "'traffic_report_Kolkata_2025-10-19_18-24-51.csv' is now ready for Tableau.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import random\n",
    "import math\n",
    "import requests        \n",
    "import urllib.parse    \n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "API_KEY = \" \" # change it with your TomTom API key\n",
    "\n",
    "PLACE_LIST = [\n",
    "    \"Kolkata, India\",\n",
    "    \"Howrah, India\",\n",
    "    \"Bidhannagar,Kolkata, India\",\n",
    "    \"Rajpur Sonarpur, India\",\n",
    "    \"Maheshtala, India\",\n",
    "    \"Serampore, India\"\n",
    "]\n",
    "\n",
    "COMBINED_PLACE_LIST = \"Kolkata\"\n",
    "\n",
    "POINTS_PER_ROAD_TYPE = 20 # Sample size per Road Type\n",
    "\n",
    "RANDOM_STATE = 77\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"traffic_report_{COMBINED_PLACE_LIST}_{timestamp}.csv\"\n",
    "OUTPUT_FILENAME = filename\n",
    "\n",
    "# --- Define the road types to process individually ---\n",
    "ROAD_TYPES_TO_PROCESS = ['motorway', 'trunk', 'primary', 'secondary','tertiary']\n",
    "\n",
    "# --- Helper functions to format TomTom's output (meters/seconds) ---\n",
    "\n",
    "def format_duration(seconds):\n",
    "    \"\"\"Converts seconds into a human-readable 'X hours Y mins' or 'Y mins' string.\"\"\"\n",
    "    if seconds is None:\n",
    "        return \"N/A\"\n",
    "    minutes = math.ceil(seconds / 60)\n",
    "    if minutes < 60:\n",
    "        return f\"{minutes} mins\"\n",
    "    else:\n",
    "        hours = minutes // 60\n",
    "        rem_minutes = minutes % 60\n",
    "        return f\"{hours} hours {rem_minutes} mins\"\n",
    "\n",
    "def format_distance(meters):\n",
    "    \"\"\"Converts meters into a human-readable 'X.Y km' string.\"\"\"\n",
    "    if meters is None:\n",
    "        return \"N/A\"\n",
    "    km = round(meters / 1000, 1)\n",
    "    return f\"{km} km\"\n",
    "\n",
    "# --- No TomTom Client Initialization needed ---\n",
    "\n",
    "# This list will hold data from all road type loops\n",
    "all_path_points_data = []\n",
    "\n",
    "print(f\"Starting traffic analysis for {PLACE_LIST}...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Main loop to process each road type separately ---\n",
    "for road_type in ROAD_TYPES_TO_PROCESS:\n",
    "    print(f\"\\nProcessing road type: '{road_type.upper()}'\")\n",
    "\n",
    "    graphs_for_this_road_type = []\n",
    "    print(f\"  Downloading '{road_type}' network from OpenStreetMap for {len(PLACE_LIST)} places...\")\n",
    "    for place in PLACE_LIST:\n",
    "        try:\n",
    "            # Fetch network for ONLY the current road type\n",
    "            road_filter = f'[\"highway\"~\"{road_type}\"]'\n",
    "            G_place = ox.graph_from_place(place, network_type='drive', custom_filter=road_filter)\n",
    "            \n",
    "            if G_place.nodes:\n",
    "                graphs_for_this_road_type.append(G_place)\n",
    "                print(f\"    - Successfully fetched '{road_type}' for {place}\")\n",
    "            else:\n",
    "                print(f\"    - No '{road_type}' roads found in {place}.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    - Error fetching data for {place}: {e}\")\n",
    "    \n",
    "    if not graphs_for_this_road_type:\n",
    "        print(f\"  - No '{road_type}' roads found in any specified location. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"  Combining {len(graphs_for_this_road_type)} graphs for '{road_type}'...\")\n",
    "    G = nx.compose_all(graphs_for_this_road_type)\n",
    "\n",
    "    try:\n",
    "        if not G.nodes:\n",
    "            print(f\"  - Combined graph for '{road_type}' is empty. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Get all points for this specific network\n",
    "        nodes = list(G.nodes)\n",
    "        all_road_points = [(G.nodes[node]['y'], G.nodes[node]['x']) for node in nodes]\n",
    "        print(f\"  Found {len(all_road_points)} total points for this road type.\")\n",
    "\n",
    "        if len(all_road_points) < 2:\n",
    "            print(f\"  - Not enough points ({len(all_road_points)}) to create paths. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Take a random sample of these points\n",
    "        random.seed(RANDOM_STATE)\n",
    "        sample_size = min(POINTS_PER_ROAD_TYPE, len(all_road_points))\n",
    "        sampled_points = random.sample(all_road_points, sample_size)\n",
    "        print(f\"  Using a random sample of {len(sampled_points)} points.\")\n",
    "\n",
    "        # Generate paths and get traffic data for this sample\n",
    "        total_paths = len(sampled_points) * (len(sampled_points) - 1)\n",
    "        path_counter = 0\n",
    "\n",
    "        if total_paths == 0:\n",
    "            print(\"  - Only one point sampled, cannot create paths. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Starting TomTom API calls for {total_paths} paths...\")\n",
    "        for i, origin in enumerate(sampled_points):\n",
    "            for j, destination in enumerate(sampled_points):\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                path_counter += 1\n",
    "                \n",
    "                # --- TomTom API Call using 'requests' ---\n",
    "                try:\n",
    "                    # TomTom uses (lat, lon)\n",
    "                    origin_str = f\"{origin[0]},{origin[1]}\"\n",
    "                    dest_str = f\"{destination[0]},{destination[1]}\"\n",
    "                    \n",
    "                    # URL-encode the location string \"lat,lon:lat,lon\"\n",
    "                    locations = urllib.parse.quote(f\"{origin_str}:{dest_str}\")\n",
    "                    \n",
    "                    # Get current time in ISO format for departure time\n",
    "                    depart_at_iso = datetime.now().isoformat()\n",
    "\n",
    "                    # Construct the API URL\n",
    "                    base_url = f\"https://api.tomtom.com/routing/1/calculateRoute/{locations}/json\"\n",
    "                    \n",
    "                    params = {\n",
    "                        'key': API_KEY,\n",
    "                        'departAt': depart_at_iso,\n",
    "                        'traffic': 'true',\n",
    "                        'computeTravelTimeFor': 'all', # Request both traffic and no-traffic times\n",
    "                        'travelMode': 'car',\n",
    "                        'routeType': 'fastest'\n",
    "                    }\n",
    "\n",
    "                    # Make the GET request\n",
    "                    response = requests.get(base_url, params=params)\n",
    "                    response.raise_for_status() # Raise an exception for bad status codes (4xx, 5xx)\n",
    "                    \n",
    "                    directions_result = response.json()\n",
    "\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"      - TomTom API Error for path {i}-to-{j}: {e}\")\n",
    "                    continue # Skip this path\n",
    "\n",
    "                if not directions_result or 'routes' not in directions_result or not directions_result['routes']:\n",
    "                    print(f\"      - No route found by TomTom for path {i}-to-{j}.\")\n",
    "                    continue\n",
    "                # --- End TomTom API Call ---\n",
    "\n",
    "                # --- Extract TomTom Info ---\n",
    "                route = directions_result['routes'][0]\n",
    "                summary = route['summary']\n",
    "\n",
    "                # TomTom provides no-traffic and with-traffic durations\n",
    "                duration_val = summary.get('noTrafficTravelTimeInSeconds')\n",
    "                duration_traffic_val = summary.get('travelTimeInSeconds')\n",
    "                distance_val_meters = summary.get('lengthInMeters')\n",
    "                \n",
    "                # Handle cases where one value might be missing\n",
    "                if duration_val is None:\n",
    "                    duration_val = duration_traffic_val\n",
    "                if duration_traffic_val is None:\n",
    "                    duration_traffic_val = duration_val\n",
    "                if duration_val is None or duration_traffic_val is None:\n",
    "                    print(f\"      - Missing duration data for path {i}-to-{j}. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Calculate congestion\n",
    "                congestion_factor = duration_traffic_val / duration_val if duration_val > 0 else 1\n",
    "\n",
    "                # TomTom provides decoded points directly in legs\n",
    "                leg = route['legs'][0]\n",
    "                decoded_path = leg['points'] # This is a list of {'latitude': y, 'longitude': x}\n",
    "\n",
    "                # Get text representations using our helper functions\n",
    "                distance_text = format_distance(distance_val_meters)\n",
    "                duration_traffic_text = format_duration(duration_traffic_val)\n",
    "                \n",
    "                path_id = f\"{road_type.capitalize()}_{i}_to_{j}\"\n",
    "                # --- End TomTom Info Extraction ---\n",
    "\n",
    "                # Append data for each point in the path to the main list\n",
    "                for order, point in enumerate(decoded_path):\n",
    "                    all_path_points_data.append({\n",
    "                        'Path_ID': path_id,\n",
    "                        'Road_Type': road_type,\n",
    "                        'Point_Order': order + 1,\n",
    "                        # Note: TomTom uses 'latitude' and 'longitude'\n",
    "                        'Latitude': point['latitude'], \n",
    "                        'Longitude': point['longitude'],\n",
    "                        'Congestion_Factor': round(congestion_factor, 2),\n",
    "                        'Distance_Text': distance_text,\n",
    "                        'Duration_in_Traffic_Text': duration_traffic_text,\n",
    "                        'Duration_Value': duration_val # Base duration without traffic\n",
    "                    })\n",
    "        print(f\"  Finished processing '{road_type}' paths.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  An error occurred while processing '{road_type}': {e}\")\n",
    "        print(\"  This might happen if the road type doesn't exist in the specified area.\")\n",
    "\n",
    "# --- Save Combined Data to a Single CSV ---\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nCombining data from all road types and saving to CSV...\")\n",
    "final__df = pd.DataFrame(all_path_points_data)\n",
    "final__df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "print(f\"\\n Successfully generated combined traffic data!\")\n",
    "print(f\"'{OUTPUT_FILENAME}' is now ready for Tableau.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b236102",
   "metadata": {},
   "source": [
    "# Using TOM TOM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e955b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tomtom\n",
      "  Downloading tomtom-1.1.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\conda\\envs\\pyenv\\lib\\site-packages (from tomtom) (2.2.0)\n",
      "Requirement already satisfied: scipy in c:\\conda\\envs\\pyenv\\lib\\site-packages (from tomtom) (1.16.1)\n",
      "Requirement already satisfied: matplotlib in c:\\conda\\envs\\pyenv\\lib\\site-packages (from tomtom) (3.10.6)\n",
      "Requirement already satisfied: pandas in c:\\conda\\envs\\pyenv\\lib\\site-packages (from tomtom) (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\conda\\envs\\pyenv\\lib\\site-packages (from tomtom) (1.7.2)\n",
      "Requirement already satisfied: statsmodels in c:\\conda\\envs\\pyenv\\lib\\site-packages (from tomtom) (0.14.5)\n",
      "Collecting librosa (from tomtom)\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting soundfile (from tomtom)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: IPython in c:\\conda\\envs\\pyenv\\lib\\site-packages (from tomtom) (9.5.0)\n",
      "Collecting plotly (from tomtom)\n",
      "  Downloading plotly-6.3.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: seaborn in c:\\conda\\envs\\pyenv\\lib\\site-packages (from tomtom) (0.13.2)\n",
      "Requirement already satisfied: notebook in c:\\conda\\envs\\pyenv\\lib\\site-packages (from tomtom) (7.4.5)\n",
      "Requirement already satisfied: jupyter in c:\\conda\\envs\\pyenv\\lib\\site-packages (from tomtom) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\conda\\envs\\pyenv\\lib\\site-packages (from IPython->tomtom) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\conda\\envs\\pyenv\\lib\\site-packages (from IPython->tomtom) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\conda\\envs\\pyenv\\lib\\site-packages (from IPython->tomtom) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from IPython->tomtom) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\conda\\envs\\pyenv\\lib\\site-packages (from IPython->tomtom) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from IPython->tomtom) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from IPython->tomtom) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\conda\\envs\\pyenv\\lib\\site-packages (from IPython->tomtom) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from IPython->tomtom) (5.14.3)\n",
      "Requirement already satisfied: wcwidth in c:\\conda\\envs\\pyenv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython->tomtom) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jedi>=0.16->IPython->tomtom) (0.8.5)\n",
      "Requirement already satisfied: jupyter-console in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter->tomtom) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter->tomtom) (7.16.6)\n",
      "Requirement already satisfied: ipykernel in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter->tomtom) (6.30.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter->tomtom) (7.8.5)\n",
      "Requirement already satisfied: jupyterlab in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter->tomtom) (4.4.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipykernel->jupyter->tomtom) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipykernel->jupyter->tomtom) (1.8.16)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipykernel->jupyter->tomtom) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipykernel->jupyter->tomtom) (5.8.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipykernel->jupyter->tomtom) (1.6.0)\n",
      "Requirement already satisfied: packaging>=22 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipykernel->jupyter->tomtom) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipykernel->jupyter->tomtom) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=25 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipykernel->jupyter->tomtom) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipykernel->jupyter->tomtom) (6.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-client>=8.0.0->ipykernel->jupyter->tomtom) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->tomtom) (4.4.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->tomtom) (311)\n",
      "Requirement already satisfied: six>=1.5 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel->jupyter->tomtom) (1.17.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipywidgets->jupyter->tomtom) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.10 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipywidgets->jupyter->tomtom) (3.6.10)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from ipywidgets->jupyter->tomtom) (1.1.11)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from notebook->tomtom) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from notebook->tomtom) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from notebook->tomtom) (0.2.4)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->tomtom) (4.10.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->tomtom) (25.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->tomtom) (3.1.6)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->tomtom) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->tomtom) (0.5.3)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->tomtom) (5.10.4)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->tomtom) (0.22.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->tomtom) (3.0.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->tomtom) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->tomtom) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->tomtom) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyterlab->jupyter->tomtom) (2.0.5)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyterlab->jupyter->tomtom) (0.28.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyterlab->jupyter->tomtom) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyterlab->jupyter->tomtom) (78.1.1)\n",
      "Requirement already satisfied: certifi in c:\\conda\\envs\\pyenv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->tomtom) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\conda\\envs\\pyenv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->tomtom) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\conda\\envs\\pyenv\\lib\\site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter->tomtom) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter->tomtom) (0.16.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->tomtom) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->tomtom) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->tomtom) (4.25.1)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->tomtom) (2.32.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (4.15.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\conda\\envs\\pyenv\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->tomtom) (25.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook->tomtom) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->tomtom) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->tomtom) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->tomtom) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->tomtom) (0.27.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (1.1.0)\n",
      "Requirement already satisfied: uri-template in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from nbconvert->jupyter->tomtom) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->tomtom) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\conda\\envs\\pyenv\\lib\\site-packages (from nbconvert->jupyter->tomtom) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\conda\\envs\\pyenv\\lib\\site-packages (from nbconvert->jupyter->tomtom) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from nbconvert->jupyter->tomtom) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from nbconvert->jupyter->tomtom) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from nbconvert->jupyter->tomtom) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\conda\\envs\\pyenv\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter->tomtom) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter->tomtom) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (2.21.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook->tomtom) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook->tomtom) (2.5.0)\n",
      "Requirement already satisfied: lark>=1.2.2 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->tomtom) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\conda\\envs\\pyenv\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->tomtom) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter->tomtom) (2.8)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->tomtom) (2.9.0.20250822)\n",
      "Collecting audioread>=2.1.9 (from librosa->tomtom)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from librosa->tomtom) (0.61.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from librosa->tomtom) (1.5.2)\n",
      "Collecting pooch>=1.1 (from librosa->tomtom)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa->tomtom)\n",
      "  Downloading soxr-1.0.0-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from librosa->tomtom) (0.4)\n",
      "Collecting msgpack>=1.0 (from librosa->tomtom)\n",
      "  Downloading msgpack-1.1.2-cp312-cp312-win_amd64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from numba>=0.51.0->librosa->tomtom) (0.44.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from scikit-learn->tomtom) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from matplotlib->tomtom) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from matplotlib->tomtom) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from matplotlib->tomtom) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from matplotlib->tomtom) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from matplotlib->tomtom) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from matplotlib->tomtom) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from pandas->tomtom) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from pandas->tomtom) (2025.2)\n",
      "Collecting narwhals>=1.15.1 (from plotly->tomtom)\n",
      "  Downloading narwhals-2.8.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from stack_data->IPython->tomtom) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from stack_data->IPython->tomtom) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\conda\\envs\\pyenv\\lib\\site-packages (from stack_data->IPython->tomtom) (0.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\conda\\envs\\pyenv\\lib\\site-packages (from statsmodels->tomtom) (1.0.1)\n",
      "Downloading tomtom-1.1.2-py3-none-any.whl (1.8 kB)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading msgpack-1.1.2-cp312-cp312-win_amd64.whl (72 kB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 0.8/1.0 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 2.1 MB/s  0:00:00\n",
      "Downloading soxr-1.0.0-cp312-abi3-win_amd64.whl (172 kB)\n",
      "Downloading plotly-6.3.1-py3-none-any.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/9.8 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/9.8 MB 2.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.6/9.8 MB 2.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.4/9.8 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.1/9.8 MB 3.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.2/9.8 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.2/9.8 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.6/9.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.6/9.8 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.8 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.8/9.8 MB 4.7 MB/s  0:00:02\n",
      "Downloading narwhals-2.8.0-py3-none-any.whl (415 kB)\n",
      "Installing collected packages: soxr, narwhals, msgpack, audioread, soundfile, pooch, plotly, librosa, tomtom\n",
      "\n",
      "   ---- ----------------------------------- 1/9 [narwhals]\n",
      "   ---- ----------------------------------- 1/9 [narwhals]\n",
      "   ---- ----------------------------------- 1/9 [narwhals]\n",
      "   ---- ----------------------------------- 1/9 [narwhals]\n",
      "   ---- ----------------------------------- 1/9 [narwhals]\n",
      "   ---- ----------------------------------- 1/9 [narwhals]\n",
      "   ---- ----------------------------------- 1/9 [narwhals]\n",
      "   ---- ----------------------------------- 1/9 [narwhals]\n",
      "   ---- ----------------------------------- 1/9 [narwhals]\n",
      "   ---- ----------------------------------- 1/9 [narwhals]\n",
      "   ------------- -------------------------- 3/9 [audioread]\n",
      "   ---------------------- ----------------- 5/9 [pooch]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   -------------------------- ------------- 6/9 [plotly]\n",
      "   ------------------------------- -------- 7/9 [librosa]\n",
      "   ------------------------------- -------- 7/9 [librosa]\n",
      "   ------------------------------- -------- 7/9 [librosa]\n",
      "   ---------------------------------------- 9/9 [tomtom]\n",
      "\n",
      "Successfully installed audioread-3.0.1 librosa-0.11.0 msgpack-1.1.2 narwhals-2.8.0 plotly-6.3.1 pooch-1.8.2 soundfile-0.13.1 soxr-1.0.0 tomtom-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tomtom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc957e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\pyenv\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting traffic analysis for ['Kolkata, India', 'Howrah, India', 'Bidhannagar,Kolkata, India', 'Rajpur Sonarpur, India', 'Maheshtala, India', 'Serampore, India']...\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing road type: 'MOTORWAY'\n",
      "  Downloading 'motorway' network from OpenStreetMap for 6 places...\n",
      "    - Successfully fetched 'motorway' for Kolkata, India\n",
      "    - Successfully fetched 'motorway' for Howrah, India\n",
      "    - Error fetching data for Bidhannagar,Kolkata, India: No data elements in server response. Check query location/filters and log.\n",
      "    - Error fetching data for Rajpur Sonarpur, India: No data elements in server response. Check query location/filters and log.\n",
      "    - Error fetching data for Maheshtala, India: No data elements in server response. Check query location/filters and log.\n",
      "    - Error fetching data for Serampore, India: Nominatim did not geocode query 'Serampore, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 2 graphs for 'motorway'...\n",
      "  Found 14 total points for this road type.\n",
      "  Using a random sample of 14 points.\n",
      "  Starting TomTom API calls for 182 paths...\n",
      "  Finished processing 'motorway' paths.\n",
      "\n",
      "Processing road type: 'TRUNK'\n",
      "  Downloading 'trunk' network from OpenStreetMap for 6 places...\n",
      "    - Successfully fetched 'trunk' for Kolkata, India\n",
      "    - Successfully fetched 'trunk' for Howrah, India\n",
      "    - Error fetching data for Bidhannagar,Kolkata, India: No data elements in server response. Check query location/filters and log.\n",
      "    - Error fetching data for Rajpur Sonarpur, India: No data elements in server response. Check query location/filters and log.\n",
      "    - Error fetching data for Maheshtala, India: No data elements in server response. Check query location/filters and log.\n",
      "    - Error fetching data for Serampore, India: Nominatim did not geocode query 'Serampore, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 2 graphs for 'trunk'...\n",
      "  Found 39 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting TomTom API calls for 380 paths...\n",
      "  Finished processing 'trunk' paths.\n",
      "\n",
      "Processing road type: 'PRIMARY'\n",
      "  Downloading 'primary' network from OpenStreetMap for 6 places...\n",
      "    - Successfully fetched 'primary' for Kolkata, India\n",
      "    - Successfully fetched 'primary' for Howrah, India\n",
      "    - Error fetching data for Bidhannagar,Kolkata, India: Found no graph nodes within the requested polygon.\n",
      "    - Successfully fetched 'primary' for Rajpur Sonarpur, India\n",
      "    - Error fetching data for Maheshtala, India: No data elements in server response. Check query location/filters and log.\n",
      "    - Error fetching data for Serampore, India: Nominatim did not geocode query 'Serampore, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 3 graphs for 'primary'...\n",
      "  Found 242 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting TomTom API calls for 380 paths...\n",
      "  Finished processing 'primary' paths.\n",
      "\n",
      "Processing road type: 'SECONDARY'\n",
      "  Downloading 'secondary' network from OpenStreetMap for 6 places...\n",
      "    - Successfully fetched 'secondary' for Kolkata, India\n",
      "    - Successfully fetched 'secondary' for Howrah, India\n",
      "    - Error fetching data for Bidhannagar,Kolkata, India: Found no graph nodes within the requested polygon.\n",
      "    - Successfully fetched 'secondary' for Rajpur Sonarpur, India\n",
      "    - Error fetching data for Maheshtala, India: Found no graph nodes within the requested polygon.\n",
      "    - Error fetching data for Serampore, India: Nominatim did not geocode query 'Serampore, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 3 graphs for 'secondary'...\n",
      "  Found 376 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting TomTom API calls for 380 paths...\n",
      "      - TomTom API Error for path 10-to-2: HTTPSConnectionPool(host='api.tomtom.com', port=443): Max retries exceeded with url: /routing/1/calculateRoute/22.5498818%2C88.330906%3A22.5835202%2C88.3796175/json?key=w1HHITdtsCFwYc6YhgmxofzUYSAjW52Q&departAt=2025-10-20T13%3A04%3A46.355805&traffic=true&computeTravelTimeFor=all&travelMode=car&routeType=fastest (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))\n",
      "  Finished processing 'secondary' paths.\n",
      "\n",
      "Processing road type: 'TERTIARY'\n",
      "  Downloading 'tertiary' network from OpenStreetMap for 6 places...\n",
      "    - Successfully fetched 'tertiary' for Kolkata, India\n",
      "    - Successfully fetched 'tertiary' for Howrah, India\n",
      "    - Error fetching data for Bidhannagar,Kolkata, India: Found no graph nodes within the requested polygon.\n",
      "    - Successfully fetched 'tertiary' for Rajpur Sonarpur, India\n",
      "    - Successfully fetched 'tertiary' for Maheshtala, India\n",
      "    - Error fetching data for Serampore, India: Nominatim did not geocode query 'Serampore, India' to a geometry of type (Multi)Polygon.\n",
      "  Combining 4 graphs for 'tertiary'...\n",
      "  Found 181 total points for this road type.\n",
      "  Using a random sample of 20 points.\n",
      "  Starting TomTom API calls for 380 paths...\n",
      "  Finished processing 'tertiary' paths.\n",
      "--------------------------------------------------\n",
      "\n",
      "Combining data from all road types and saving to CSV...\n",
      "\n",
      " Successfully generated combined traffic data!\n",
      "'traffic_report_Kolkata_2025-10-20_12-17-06.csv' is now ready for Tableau.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import random\n",
    "import math\n",
    "import requests        \n",
    "import urllib.parse    \n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "API_KEY = \" \" # change it with your TomTom API key\n",
    "\n",
    "PLACE_LIST = [\n",
    "    \"Kolkata, India\",\n",
    "    \"Howrah, India\",\n",
    "    \"Bidhannagar,Kolkata, India\",\n",
    "    \"Rajpur Sonarpur, India\",\n",
    "    \"Maheshtala, India\",\n",
    "    \"Serampore, India\"\n",
    "]\n",
    "\n",
    "COMBINED_PLACE_LIST = \"Kolkata\"\n",
    "\n",
    "POINTS_PER_ROAD_TYPE = 20 # Sample size per Road Type\n",
    "\n",
    "RANDOM_STATE = 77\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"traffic_report_{COMBINED_PLACE_LIST}_{timestamp}.csv\"\n",
    "OUTPUT_FILENAME = filename\n",
    "\n",
    "# --- Define the road types to process individually ---\n",
    "ROAD_TYPES_TO_PROCESS = ['motorway', 'trunk', 'primary', 'secondary','tertiary']\n",
    "\n",
    "# --- Helper functions to format TomTom's output (meters/seconds) ---\n",
    "\n",
    "def format_duration(seconds):\n",
    "    \"\"\"Converts seconds into a human-readable 'X hours Y mins' or 'Y mins' string.\"\"\"\n",
    "    if seconds is None:\n",
    "        return \"N/A\"\n",
    "    minutes = math.ceil(seconds / 60)\n",
    "    if minutes < 60:\n",
    "        return f\"{minutes} mins\"\n",
    "    else:\n",
    "        hours = minutes // 60\n",
    "        rem_minutes = minutes % 60\n",
    "        return f\"{hours} hours {rem_minutes} mins\"\n",
    "\n",
    "def format_distance(meters):\n",
    "    \"\"\"Converts meters into a human-readable 'X.Y km' string.\"\"\"\n",
    "    if meters is None:\n",
    "        return \"N/A\"\n",
    "    km = round(meters / 1000, 1)\n",
    "    return f\"{km} km\"\n",
    "\n",
    "# --- No TomTom Client Initialization needed ---\n",
    "\n",
    "# This list will hold data from all road type loops\n",
    "all_path_points_data = []\n",
    "\n",
    "print(f\"Starting traffic analysis for {PLACE_LIST}...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Main loop to process each road type separately ---\n",
    "for road_type in ROAD_TYPES_TO_PROCESS:\n",
    "    print(f\"\\nProcessing road type: '{road_type.upper()}'\")\n",
    "\n",
    "    graphs_for_this_road_type = []\n",
    "    print(f\"  Downloading '{road_type}' network from OpenStreetMap for {len(PLACE_LIST)} places...\")\n",
    "    for place in PLACE_LIST:\n",
    "        try:\n",
    "            # Fetch network for ONLY the current road type\n",
    "            road_filter = f'[\"highway\"~\"{road_type}\"]'\n",
    "            G_place = ox.graph_from_place(place, network_type='drive', custom_filter=road_filter)\n",
    "            \n",
    "            if G_place.nodes:\n",
    "                graphs_for_this_road_type.append(G_place)\n",
    "                print(f\"    - Successfully fetched '{road_type}' for {place}\")\n",
    "            else:\n",
    "                print(f\"    - No '{road_type}' roads found in {place}.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    - Error fetching data for {place}: {e}\")\n",
    "    \n",
    "    if not graphs_for_this_road_type:\n",
    "        print(f\"  - No '{road_type}' roads found in any specified location. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"  Combining {len(graphs_for_this_road_type)} graphs for '{road_type}'...\")\n",
    "    G = nx.compose_all(graphs_for_this_road_type)\n",
    "\n",
    "    try:\n",
    "        if not G.nodes:\n",
    "            print(f\"  - Combined graph for '{road_type}' is empty. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Get all points for this specific network\n",
    "        nodes = list(G.nodes)\n",
    "        all_road_points = [(G.nodes[node]['y'], G.nodes[node]['x']) for node in nodes]\n",
    "        print(f\"  Found {len(all_road_points)} total points for this road type.\")\n",
    "\n",
    "        if len(all_road_points) < 2:\n",
    "            print(f\"  - Not enough points ({len(all_road_points)}) to create paths. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Take a random sample of these points\n",
    "        random.seed(RANDOM_STATE)\n",
    "        sample_size = min(POINTS_PER_ROAD_TYPE, len(all_road_points))\n",
    "        sampled_points = random.sample(all_road_points, sample_size)\n",
    "        print(f\"  Using a random sample of {len(sampled_points)} points.\")\n",
    "\n",
    "        # Generate paths and get traffic data for this sample\n",
    "        total_paths = len(sampled_points) * (len(sampled_points) - 1)\n",
    "        path_counter = 0\n",
    "\n",
    "        if total_paths == 0:\n",
    "            print(\"  - Only one point sampled, cannot create paths. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  Starting TomTom API calls for {total_paths} paths...\")\n",
    "        for i, origin in enumerate(sampled_points):\n",
    "            for j, destination in enumerate(sampled_points):\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                path_counter += 1\n",
    "                \n",
    "                # --- TomTom API Call using 'requests' ---\n",
    "                try:\n",
    "                    # TomTom uses (lat, lon)\n",
    "                    origin_str = f\"{origin[0]},{origin[1]}\"\n",
    "                    dest_str = f\"{destination[0]},{destination[1]}\"\n",
    "                    \n",
    "                    # URL-encode the location string \"lat,lon:lat,lon\"\n",
    "                    locations = urllib.parse.quote(f\"{origin_str}:{dest_str}\")\n",
    "                    \n",
    "                    # Get current time in ISO format for departure time\n",
    "                    depart_at_iso = datetime.now().isoformat()\n",
    "\n",
    "                    # Construct the API URL\n",
    "                    base_url = f\"https://api.tomtom.com/routing/1/calculateRoute/{locations}/json\"\n",
    "                    \n",
    "                    params = {\n",
    "                        'key': API_KEY,\n",
    "                        'departAt': depart_at_iso,\n",
    "                        'traffic': 'true',\n",
    "                        'computeTravelTimeFor': 'all', # Request both traffic and no-traffic times\n",
    "                        'travelMode': 'car',\n",
    "                        'routeType': 'fastest'\n",
    "                    }\n",
    "\n",
    "                    # Make the GET request\n",
    "                    response = requests.get(base_url, params=params)\n",
    "                    response.raise_for_status() # Raise an exception for bad status codes (4xx, 5xx)\n",
    "                    \n",
    "                    directions_result = response.json()\n",
    "\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"      - TomTom API Error for path {i}-to-{j}: {e}\")\n",
    "                    continue # Skip this path\n",
    "\n",
    "                if not directions_result or 'routes' not in directions_result or not directions_result['routes']:\n",
    "                    print(f\"      - No route found by TomTom for path {i}-to-{j}.\")\n",
    "                    continue\n",
    "                # --- End TomTom API Call ---\n",
    "\n",
    "                # --- Extract TomTom Info ---\n",
    "                route = directions_result['routes'][0]\n",
    "                summary = route['summary']\n",
    "\n",
    "                # TomTom provides no-traffic and with-traffic durations\n",
    "                duration_val = summary.get('noTrafficTravelTimeInSeconds')\n",
    "                duration_traffic_val = summary.get('travelTimeInSeconds')\n",
    "                distance_val_meters = summary.get('lengthInMeters')\n",
    "                \n",
    "                # Handle cases where one value might be missing\n",
    "                if duration_val is None:\n",
    "                    duration_val = duration_traffic_val\n",
    "                if duration_traffic_val is None:\n",
    "                    duration_traffic_val = duration_val\n",
    "                if duration_val is None or duration_traffic_val is None:\n",
    "                    print(f\"      - Missing duration data for path {i}-to-{j}. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Calculate congestion\n",
    "                congestion_factor = duration_traffic_val / duration_val if duration_val > 0 else 1\n",
    "\n",
    "                # TomTom provides decoded points directly in legs\n",
    "                leg = route['legs'][0]\n",
    "                decoded_path = leg['points'] # This is a list of {'latitude': y, 'longitude': x}\n",
    "\n",
    "                # Get text representations using our helper functions\n",
    "                distance_text = format_distance(distance_val_meters)\n",
    "                duration_traffic_text = format_duration(duration_traffic_val)\n",
    "                \n",
    "                path_id = f\"{road_type.capitalize()}_{i}_to_{j}\"\n",
    "                # --- End TomTom Info Extraction ---\n",
    "\n",
    "                # Append data for each point in the path to the main list\n",
    "                for order, point in enumerate(decoded_path):\n",
    "                    all_path_points_data.append({\n",
    "                        'Path_ID': path_id,\n",
    "                        'Road_Type': road_type,\n",
    "                        'Point_Order': order + 1,\n",
    "                        # Note: TomTom uses 'latitude' and 'longitude'\n",
    "                        'Latitude': point['latitude'], \n",
    "                        'Longitude': point['longitude'],\n",
    "                        'Congestion_Factor': round(congestion_factor, 2),\n",
    "                        'Distance_Text': distance_text,\n",
    "                        'Duration_in_Traffic_Text': duration_traffic_text,\n",
    "                        'Duration_Value': duration_val # Base duration without traffic\n",
    "                    })\n",
    "        print(f\"  Finished processing '{road_type}' paths.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  An error occurred while processing '{road_type}': {e}\")\n",
    "        print(\"  This might happen if the road type doesn't exist in the specified area.\")\n",
    "\n",
    "# --- Save Combined Data to a Single CSV ---\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nCombining data from all road types and saving to CSV...\")\n",
    "final__df = pd.DataFrame(all_path_points_data)\n",
    "final__df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "print(f\"\\n Successfully generated combined traffic data!\")\n",
    "print(f\"'{OUTPUT_FILENAME}' is now ready for Tableau.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7021cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path_ID</th>\n",
       "      <th>Road_Type</th>\n",
       "      <th>Point_Order</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Congestion_Factor</th>\n",
       "      <th>Distance_Text</th>\n",
       "      <th>Duration_in_Traffic_Text</th>\n",
       "      <th>Duration_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Motorway_0_to_1</td>\n",
       "      <td>motorway</td>\n",
       "      <td>1</td>\n",
       "      <td>22.56346</td>\n",
       "      <td>88.31833</td>\n",
       "      <td>1.06</td>\n",
       "      <td>12.9 km</td>\n",
       "      <td>22 mins</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Motorway_0_to_1</td>\n",
       "      <td>motorway</td>\n",
       "      <td>2</td>\n",
       "      <td>22.56351</td>\n",
       "      <td>88.31827</td>\n",
       "      <td>1.06</td>\n",
       "      <td>12.9 km</td>\n",
       "      <td>22 mins</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Motorway_0_to_1</td>\n",
       "      <td>motorway</td>\n",
       "      <td>3</td>\n",
       "      <td>22.56364</td>\n",
       "      <td>88.31807</td>\n",
       "      <td>1.06</td>\n",
       "      <td>12.9 km</td>\n",
       "      <td>22 mins</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Motorway_0_to_1</td>\n",
       "      <td>motorway</td>\n",
       "      <td>4</td>\n",
       "      <td>22.56383</td>\n",
       "      <td>88.31778</td>\n",
       "      <td>1.06</td>\n",
       "      <td>12.9 km</td>\n",
       "      <td>22 mins</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Motorway_0_to_1</td>\n",
       "      <td>motorway</td>\n",
       "      <td>5</td>\n",
       "      <td>22.56397</td>\n",
       "      <td>88.31791</td>\n",
       "      <td>1.06</td>\n",
       "      <td>12.9 km</td>\n",
       "      <td>22 mins</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338644</th>\n",
       "      <td>Tertiary_8_to_0</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>436</td>\n",
       "      <td>22.44373</td>\n",
       "      <td>88.41757</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.5 km</td>\n",
       "      <td>35 mins</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338645</th>\n",
       "      <td>Tertiary_8_to_0</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>437</td>\n",
       "      <td>22.44373</td>\n",
       "      <td>88.41761</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.5 km</td>\n",
       "      <td>35 mins</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338646</th>\n",
       "      <td>Tertiary_8_to_0</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>438</td>\n",
       "      <td>22.44374</td>\n",
       "      <td>88.41797</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.5 km</td>\n",
       "      <td>35 mins</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338647</th>\n",
       "      <td>Tertiary_8_to_0</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>439</td>\n",
       "      <td>22.44374</td>\n",
       "      <td>88.41801</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.5 km</td>\n",
       "      <td>35 mins</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338648</th>\n",
       "      <td>Tertiary_8_to_0</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>440</td>\n",
       "      <td>22.44374</td>\n",
       "      <td>88.41808</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.5 km</td>\n",
       "      <td>35 mins</td>\n",
       "      <td>2078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338649 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Path_ID Road_Type  Point_Order  Latitude  Longitude  \\\n",
       "0       Motorway_0_to_1  motorway            1  22.56346   88.31833   \n",
       "1       Motorway_0_to_1  motorway            2  22.56351   88.31827   \n",
       "2       Motorway_0_to_1  motorway            3  22.56364   88.31807   \n",
       "3       Motorway_0_to_1  motorway            4  22.56383   88.31778   \n",
       "4       Motorway_0_to_1  motorway            5  22.56397   88.31791   \n",
       "...                 ...       ...          ...       ...        ...   \n",
       "338644  Tertiary_8_to_0  tertiary          436  22.44373   88.41757   \n",
       "338645  Tertiary_8_to_0  tertiary          437  22.44373   88.41761   \n",
       "338646  Tertiary_8_to_0  tertiary          438  22.44374   88.41797   \n",
       "338647  Tertiary_8_to_0  tertiary          439  22.44374   88.41801   \n",
       "338648  Tertiary_8_to_0  tertiary          440  22.44374   88.41808   \n",
       "\n",
       "        Congestion_Factor Distance_Text Duration_in_Traffic_Text  \\\n",
       "0                    1.06       12.9 km                  22 mins   \n",
       "1                    1.06       12.9 km                  22 mins   \n",
       "2                    1.06       12.9 km                  22 mins   \n",
       "3                    1.06       12.9 km                  22 mins   \n",
       "4                    1.06       12.9 km                  22 mins   \n",
       "...                   ...           ...                      ...   \n",
       "338644               1.00       16.5 km                  35 mins   \n",
       "338645               1.00       16.5 km                  35 mins   \n",
       "338646               1.00       16.5 km                  35 mins   \n",
       "338647               1.00       16.5 km                  35 mins   \n",
       "338648               1.00       16.5 km                  35 mins   \n",
       "\n",
       "        Duration_Value  \n",
       "0                 1201  \n",
       "1                 1201  \n",
       "2                 1201  \n",
       "3                 1201  \n",
       "4                 1201  \n",
       "...                ...  \n",
       "338644            2078  \n",
       "338645            2078  \n",
       "338646            2078  \n",
       "338647            2078  \n",
       "338648            2078  \n",
       "\n",
       "[338649 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final__df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a686bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final__df.to_csv(OUTPUT_FILENAME, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823ef363",
   "metadata": {},
   "source": [
    "# Getting economic hubs of an country example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d97a8a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Economic Hotspot Collection ---\n",
      "\n",
      "Searching for category: 'Commercial'...\n",
      "  Using query: 'business park in Delhi NCR'\n",
      "  Using query: 'IT park in Gurgaon'\n",
      "  Using query: 'corporate office in Noida'\n",
      "\n",
      "Searching for category: 'Retail'...\n",
      "  Using query: 'shopping mall in Delhi NCR'\n",
      "  Using query: 'major market in Delhi'\n",
      "\n",
      "Searching for category: 'Industrial'...\n",
      "  Using query: 'industrial area in Delhi NCR'\n",
      "  Using query: 'factory in Faridabad'\n",
      "\n",
      "Searching for category: 'Transit Hub'...\n",
      "  Using query: 'major metro station in Delhi'\n",
      "  Using query: 'major railway station in Delhi'\n",
      "\n",
      "--- Collection Complete! ---\n",
      "Saved 129 unique economic hotspots to 'economic_hotspots.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "\n",
    "# --- Configuration ---\n",
    "API_KEY = \"Api key \"\n",
    "OUTPUT_FILENAME = \"economic_hotspots.csv\"\n",
    "\n",
    "AREA_BOUNDS = {\n",
    "    \"sw\": (28.341944, 76.811111),\n",
    "    \"ne\": (28.928889, 77.473056)\n",
    "}\n",
    "\n",
    "ECONOMIC_CATEGORIES = {\n",
    "    \"Commercial\": [\"business park in Delhi NCR\", \"IT park in Gurgaon\", \"corporate office in Noida\"],\n",
    "    \"Retail\": [\"shopping mall in Delhi NCR\", \"major market in Delhi\"],\n",
    "    \"Industrial\": [\"industrial area in Delhi NCR\", \"factory in Faridabad\"],\n",
    "    \"Transit Hub\": [\"major metro station in Delhi\", \"major railway station in Delhi\"]\n",
    "}\n",
    "\n",
    "\n",
    "def get_area_center_and_radius(bounds):\n",
    "    \"\"\"Calculates the center and radius of the bounding box to focus the search.\"\"\"\n",
    "    center_lat = (bounds['sw'][0] + bounds['ne'][0]) / 2\n",
    "    center_lon = (bounds['sw'][1] + bounds['ne'][1]) / 2\n",
    "    R = 6371000\n",
    "    lat1, lon1 = math.radians(center_lat), math.radians(center_lon)\n",
    "    lat2, lon2 = math.radians(bounds['ne'][0]), math.radians(bounds['ne'][1])\n",
    "    dlon, dlat = lon2 - lon1, lat2 - lat1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1)*math.cos(lat2)*math.sin(dlon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    radius = R * c\n",
    "    return ((center_lat, center_lon), radius)\n",
    "\n",
    "\n",
    "def search_places_new_api(query, location, radius, api_key):\n",
    "    \"\"\"Uses the new Places API (v1) text search.\"\"\"\n",
    "    url = \"https://places.googleapis.com/v1/places:searchText\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"X-Goog-Api-Key\": api_key,\n",
    "        \"X-Goog-FieldMask\": \"places.displayName,places.id,places.formattedAddress,places.location\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"textQuery\": query,\n",
    "        \"locationBias\": {\n",
    "            \"circle\": {\n",
    "                \"center\": {\"latitude\": location[0], \"longitude\": location[1]},\n",
    "                \"radius\": radius\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Places API Error ({response.status_code}): {response.text}\")\n",
    "        return []\n",
    "    data = response.json()\n",
    "    return data.get(\"places\", [])\n",
    "\n",
    "\n",
    "def collect_hotspots():\n",
    "    print(\"--- Starting Economic Hotspot Collection ---\")\n",
    "\n",
    "    search_center, search_radius = get_area_center_and_radius(AREA_BOUNDS)\n",
    "    unique_places = {}\n",
    "\n",
    "    for category, queries in ECONOMIC_CATEGORIES.items():\n",
    "        print(f\"\\nSearching for category: '{category}'...\")\n",
    "        for query in queries:\n",
    "            print(f\"  Using query: '{query}'\")\n",
    "            try:\n",
    "                results = search_places_new_api(query, search_center, search_radius, API_KEY)\n",
    "                for place in results:\n",
    "                    place_id = place.get(\"id\")\n",
    "                    if place_id not in unique_places:\n",
    "                        loc = place[\"location\"]\n",
    "                        unique_places[place_id] = {\n",
    "                            \"Name\": place[\"displayName\"][\"text\"],\n",
    "                            \"Category\": category,\n",
    "                            \"Latitude\": loc[\"latitude\"],\n",
    "                            \"Longitude\": loc[\"longitude\"],\n",
    "                            \"Address\": place.get(\"formattedAddress\", \"N/A\")\n",
    "                        }\n",
    "                time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(f\"    -> Error during search for '{query}': {e}\")\n",
    "\n",
    "    if not unique_places:\n",
    "        print(\"No hotspots were found. Check API key or quota limits.\")\n",
    "        return\n",
    "\n",
    "    hotspots_df = pd.DataFrame(unique_places.values())\n",
    "    hotspots_df.to_csv(OUTPUT_FILENAME, index=False)\n",
    "    print(f\"\\n--- Collection Complete! ---\")\n",
    "    print(f\"Saved {len(hotspots_df)} unique economic hotspots to '{OUTPUT_FILENAME}'\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    collect_hotspots()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fbfcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Latitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Longitude",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Address",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f8f0b818-4417-4978-8090-8a551c043a26",
       "rows": [
        [
         "0",
         "Best Business Park",
         "Commercial",
         "28.6918972",
         "77.1474539",
         "plot no. P, 2, Netaji Subhash Place, Shakurpur, Delhi, 110034, India"
        ],
        [
         "1",
         "DLF Corporate Park",
         "Commercial",
         "28.482756",
         "77.1051404",
         "Moulsari Ave, Garden Estate, DLF Phase 3, Sector 24, Gurugram, Haryana 122010, India"
        ],
        [
         "2",
         "Global Business Park",
         "Commercial",
         "28.4812306",
         "77.102032",
         "Mehrauli-Gurgaon Rd, Sikanderpur, Sector 26, Gurugram, Haryana 122002, India"
        ],
        [
         "3",
         "Embassy Galaxy Business Park",
         "Commercial",
         "28.6244435",
         "77.37024720000001",
         "A-44 & 45, Sushil Marg, Block A, Industrial Area, Sector 62, Noida, Uttar Pradesh 201309, India"
        ],
        [
         "4",
         "NSIC Business park",
         "Commercial",
         "28.5514439",
         "77.2654605",
         "Software Technology Park, FB-05, NSIC, NSIC Estate, Okhla Phase III, Okhla Industrial Estate, New Delhi, Delhi 110020, India"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Business Park</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>28.691897</td>\n",
       "      <td>77.147454</td>\n",
       "      <td>plot no. P, 2, Netaji Subhash Place, Shakurpur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DLF Corporate Park</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>28.482756</td>\n",
       "      <td>77.105140</td>\n",
       "      <td>Moulsari Ave, Garden Estate, DLF Phase 3, Sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global Business Park</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>28.481231</td>\n",
       "      <td>77.102032</td>\n",
       "      <td>Mehrauli-Gurgaon Rd, Sikanderpur, Sector 26, G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embassy Galaxy Business Park</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>28.624444</td>\n",
       "      <td>77.370247</td>\n",
       "      <td>A-44 &amp; 45, Sushil Marg, Block A, Industrial Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NSIC Business park</td>\n",
       "      <td>Commercial</td>\n",
       "      <td>28.551444</td>\n",
       "      <td>77.265461</td>\n",
       "      <td>Software Technology Park, FB-05, NSIC, NSIC Es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name    Category   Latitude  Longitude  \\\n",
       "0            Best Business Park  Commercial  28.691897  77.147454   \n",
       "1            DLF Corporate Park  Commercial  28.482756  77.105140   \n",
       "2          Global Business Park  Commercial  28.481231  77.102032   \n",
       "3  Embassy Galaxy Business Park  Commercial  28.624444  77.370247   \n",
       "4            NSIC Business park  Commercial  28.551444  77.265461   \n",
       "\n",
       "                                             Address  \n",
       "0  plot no. P, 2, Netaji Subhash Place, Shakurpur...  \n",
       "1  Moulsari Ave, Garden Estate, DLF Phase 3, Sect...  \n",
       "2  Mehrauli-Gurgaon Rd, Sikanderpur, Sector 26, G...  \n",
       "3  A-44 & 45, Sushil Marg, Block A, Industrial Ar...  \n",
       "4  Software Technology Park, FB-05, NSIC, NSIC Es...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economic_hotspots = pd.read_csv(\"economic_hotspots.csv\")\n",
    "economic_hotspots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15884178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
